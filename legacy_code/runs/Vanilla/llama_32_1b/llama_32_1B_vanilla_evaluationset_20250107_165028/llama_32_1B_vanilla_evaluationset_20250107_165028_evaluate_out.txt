2025-01-07 16:50:32,551 INFO     Loading settings and stats
2025-01-07 16:50:32,551 INFO     Using prompt: , temperature: 0.1
2025-01-07 16:50:32,553 DEBUG    Settings loaded. CSV path: /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/tobias/SynMOF_M_out.csv
2025-01-07 16:50:32,554 WARNING  [Errno 2] No such file or directory: 'stats_llama_32_1B_vanilla_evaluationset_20250107_165028.yml'
2025-01-07 16:50:32,554 WARNING  [Errno 2] No such file or directory: 'stats_llama_32_1B_vanilla_evaluationset_20250107_165028.yaml'
2025-01-07 16:50:32,554 WARNING  Could not load 'stats_llama_32_1B_vanilla_evaluationset_20250107_165028.yml', creating it (empty)
2025-01-07 16:50:32,555 INFO     Loading labels from CSV file: /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/tobias/SynMOF_M_out.csv
2025-01-07 16:50:32,560 INFO     Found 778 paragraphs with labels
2025-01-07 16:50:32,560 DEBUG    First few valid IDs: ['XIFLOP_clean', 'YOFGOR_clean', 'SOBZEQ_clean', 'YOJMAN_clean', 'GABYUG_clean']
2025-01-07 16:50:32,560 INFO     Loading evaluation set instead of regular dataset.
2025-01-07 16:50:32,560 DEBUG    Already evaluated: 0 items
2025-01-07 16:50:32,560 INFO     Loading Dataset from /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/eval_paragraphs
2025-01-07 16:50:32,560 INFO     Loading MOFDataset from '/gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/eval_paragraphs'
2025-01-07 16:50:32,565 INFO     Dataset loaded with 77 items
2025-01-07 16:50:32,565 INFO     Found 77 paragraphs that have labels in dataset
2025-01-07 16:50:32,565 DEBUG    First few overlapping IDs: ['ILAGUY_charged', 'MAZSUD_clean', 'PUWCOZ_clean', 'RUVKAV_clean', 'TUBJAD_clean']
2025-01-07 16:50:32,565 INFO     Processing model: LLaMa 3.2 1B Instruct
2025-01-07 16:50:32,566 INFO       0%|          | 0/77 [00:00<?, ?it/s, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:32,567 INFO     Loading Model [LLaMa 3.2 1B Instruct] from /home/iti/zn2950/home/haicore_ws/base_models/Llama-3.2-1B-Instruct
2025-01-07 16:50:33,181 INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
2025-01-07 16:50:37,197 INFO       1%|▏         | 1/77 [00:04<05:51,  4.63s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:38,504 INFO       3%|▎         | 2/77 [00:05<03:20,  2.68s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:39,778 INFO       4%|▍         | 3/77 [00:07<02:30,  2.04s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:41,101 INFO       5%|▌         | 4/77 [00:08<02:08,  1.75s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:42,448 INFO       6%|▋         | 5/77 [00:09<01:55,  1.61s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:43,693 INFO       8%|▊         | 6/77 [00:11<01:45,  1.48s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:44,925 INFO       9%|▉         | 7/77 [00:12<01:38,  1.40s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:46,165 INFO      10%|█         | 8/77 [00:13<01:33,  1.35s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:47,428 INFO      12%|█▏        | 9/77 [00:14<01:29,  1.32s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:48,666 INFO      13%|█▎        | 10/77 [00:16<01:26,  1.30s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:50,033 INFO      14%|█▍        | 11/77 [00:17<01:26,  1.32s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:51,337 INFO      16%|█▌        | 12/77 [00:18<01:25,  1.31s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:52,658 INFO      17%|█▋        | 13/77 [00:20<01:24,  1.32s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:53,976 INFO      18%|█▊        | 14/77 [00:21<01:22,  1.32s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:55,290 INFO      19%|█▉        | 15/77 [00:22<01:21,  1.32s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:56,625 INFO      21%|██        | 16/77 [00:24<01:20,  1.32s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:57,904 INFO      22%|██▏       | 17/77 [00:25<01:18,  1.31s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:59,144 INFO      23%|██▎       | 18/77 [00:26<01:16,  1.29s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:00,493 INFO      25%|██▍       | 19/77 [00:27<01:15,  1.31s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:01,786 INFO     Saving progress to `stats_llama_32_1B_vanilla_evaluationset_20250107_165028.yml`
2025-01-07 16:51:01,799 INFO      26%|██▌       | 20/77 [00:29<01:14,  1.31s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:03,150 INFO      27%|██▋       | 21/77 [00:30<01:13,  1.32s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:04,450 INFO      29%|██▊       | 22/77 [00:31<01:12,  1.31s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:05,760 INFO      30%|██▉       | 23/77 [00:33<01:10,  1.31s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:07,009 INFO      31%|███       | 24/77 [00:34<01:08,  1.29s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:08,338 INFO      32%|███▏      | 25/77 [00:35<01:07,  1.30s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:09,661 INFO      34%|███▍      | 26/77 [00:37<01:06,  1.31s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:10,992 INFO      35%|███▌      | 27/77 [00:38<01:05,  1.32s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:12,253 INFO      36%|███▋      | 28/77 [00:39<01:03,  1.30s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:13,591 INFO      38%|███▊      | 29/77 [00:41<01:02,  1.31s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:14,821 INFO      39%|███▉      | 30/77 [00:42<01:00,  1.29s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:16,108 INFO      40%|████      | 31/77 [00:43<00:59,  1.29s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:17,466 INFO      42%|████▏     | 32/77 [00:44<00:58,  1.31s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:18,786 INFO      43%|████▎     | 33/77 [00:46<00:57,  1.31s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:20,114 INFO      44%|████▍     | 34/77 [00:47<00:56,  1.32s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:21,353 INFO      45%|████▌     | 35/77 [00:48<00:54,  1.29s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:22,602 INFO      47%|████▋     | 36/77 [00:50<00:52,  1.28s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:23,915 INFO      48%|████▊     | 37/77 [00:51<00:51,  1.29s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:25,319 INFO      49%|████▉     | 38/77 [00:52<00:51,  1.32s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:26,549 INFO      51%|█████     | 39/77 [00:53<00:49,  1.30s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:27,763 INFO     Saving progress to `stats_llama_32_1B_vanilla_evaluationset_20250107_165028.yml`
2025-01-07 16:51:27,788 INFO      52%|█████▏    | 40/77 [00:55<00:47,  1.28s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:29,048 INFO      53%|█████▎    | 41/77 [00:56<00:45,  1.27s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:30,366 INFO      55%|█████▍    | 42/77 [00:57<00:45,  1.29s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:31,631 INFO      56%|█████▌    | 43/77 [00:59<00:43,  1.28s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:32,951 INFO      57%|█████▋    | 44/77 [01:00<00:42,  1.29s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:34,259 INFO      58%|█████▊    | 45/77 [01:01<00:41,  1.30s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:35,502 INFO      60%|█████▉    | 46/77 [01:02<00:39,  1.28s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:36,802 INFO      61%|██████    | 47/77 [01:04<00:38,  1.29s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:38,123 INFO      62%|██████▏   | 48/77 [01:05<00:37,  1.30s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:39,419 INFO      64%|██████▎   | 49/77 [01:06<00:36,  1.30s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:40,761 INFO      65%|██████▍   | 50/77 [01:08<00:35,  1.31s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:41,988 INFO      66%|██████▌   | 51/77 [01:09<00:33,  1.29s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:43,311 INFO      68%|██████▊   | 52/77 [01:10<00:32,  1.30s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:44,623 INFO      69%|██████▉   | 53/77 [01:12<00:31,  1.30s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:45,927 INFO      70%|███████   | 54/77 [01:13<00:29,  1.30s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:47,243 INFO      71%|███████▏  | 55/77 [01:14<00:28,  1.31s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:48,556 INFO      73%|███████▎  | 56/77 [01:15<00:27,  1.31s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:49,802 INFO      74%|███████▍  | 57/77 [01:17<00:25,  1.29s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:51,104 INFO      75%|███████▌  | 58/77 [01:18<00:24,  1.29s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:52,408 INFO      77%|███████▋  | 59/77 [01:19<00:23,  1.30s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:53,726 INFO     Saving progress to `stats_llama_32_1B_vanilla_evaluationset_20250107_165028.yml`
2025-01-07 16:51:53,762 INFO      78%|███████▊  | 60/77 [01:21<00:22,  1.31s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:55,013 INFO      79%|███████▉  | 61/77 [01:22<00:20,  1.29s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:56,277 INFO      81%|████████  | 62/77 [01:23<00:19,  1.29s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:57,613 INFO      82%|████████▏ | 63/77 [01:25<00:18,  1.30s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:59,011 INFO      83%|████████▎ | 64/77 [01:26<00:17,  1.33s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:52:00,303 INFO      84%|████████▍ | 65/77 [01:27<00:15,  1.32s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:52:01,545 INFO      86%|████████▌ | 66/77 [01:28<00:14,  1.30s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:52:02,938 INFO      87%|████████▋ | 67/77 [01:30<00:13,  1.32s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:52:04,309 INFO      88%|████████▊ | 68/77 [01:31<00:12,  1.34s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:52:05,622 INFO      90%|████████▉ | 69/77 [01:33<00:10,  1.33s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:52:06,911 INFO      91%|█████████ | 70/77 [01:34<00:09,  1.32s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:52:08,259 INFO      92%|█████████▏| 71/77 [01:35<00:07,  1.33s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:52:09,504 INFO      94%|█████████▎| 72/77 [01:36<00:06,  1.30s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:52:10,810 INFO      95%|█████████▍| 73/77 [01:38<00:05,  1.30s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:52:12,040 INFO      96%|█████████▌| 74/77 [01:39<00:03,  1.28s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:52:13,388 INFO      97%|█████████▋| 75/77 [01:40<00:02,  1.30s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:52:14,665 INFO      99%|█████████▊| 76/77 [01:42<00:01,  1.29s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:52:15,928 INFO     Saving progress to `stats_llama_32_1B_vanilla_evaluationset_20250107_165028.yml`
2025-01-07 16:52:15,973 INFO     Processing model: LLaMa 3.2 3B Instruct
2025-01-07 16:52:15,973 INFO     Skipping model [LLaMa 3.2 3B Instruct]
  0%|          | 0/77 [00:00<?, ?it/s, LLaMa 3.2 1B Instruct]
model kwargs: {'torch_dtype': torch.float16, 'load_in_8bit': False, 'trust_remote_code': True, 'device_map': 'auto', 'do_sample': True}
  1%|▏         | 1/77 [00:04<05:51,  4.63s/it, LLaMa 3.2 1B Instruct]
  3%|▎         | 2/77 [00:05<03:20,  2.68s/it, LLaMa 3.2 1B Instruct]
  4%|▍         | 3/77 [00:07<02:30,  2.04s/it, LLaMa 3.2 1B Instruct]
  5%|▌         | 4/77 [00:08<02:08,  1.75s/it, LLaMa 3.2 1B Instruct]
  6%|▋         | 5/77 [00:09<01:55,  1.61s/it, LLaMa 3.2 1B Instruct]
  8%|▊         | 6/77 [00:11<01:45,  1.48s/it, LLaMa 3.2 1B Instruct]
  9%|▉         | 7/77 [00:12<01:38,  1.40s/it, LLaMa 3.2 1B Instruct]
 10%|█         | 8/77 [00:13<01:33,  1.35s/it, LLaMa 3.2 1B Instruct]
 12%|█▏        | 9/77 [00:14<01:29,  1.32s/it, LLaMa 3.2 1B Instruct]
 13%|█▎        | 10/77 [00:16<01:26,  1.30s/it, LLaMa 3.2 1B Instruct]
 14%|█▍        | 11/77 [00:17<01:26,  1.32s/it, LLaMa 3.2 1B Instruct]
 16%|█▌        | 12/77 [00:18<01:25,  1.31s/it, LLaMa 3.2 1B Instruct]
 17%|█▋        | 13/77 [00:20<01:24,  1.32s/it, LLaMa 3.2 1B Instruct]
 18%|█▊        | 14/77 [00:21<01:22,  1.32s/it, LLaMa 3.2 1B Instruct]
 19%|█▉        | 15/77 [00:22<01:21,  1.32s/it, LLaMa 3.2 1B Instruct]
 21%|██        | 16/77 [00:24<01:20,  1.32s/it, LLaMa 3.2 1B Instruct]
 22%|██▏       | 17/77 [00:25<01:18,  1.31s/it, LLaMa 3.2 1B Instruct]
 23%|██▎       | 18/77 [00:26<01:16,  1.29s/it, LLaMa 3.2 1B Instruct]
 25%|██▍       | 19/77 [00:27<01:15,  1.31s/it, LLaMa 3.2 1B Instruct]
 26%|██▌       | 20/77 [00:29<01:14,  1.31s/it, LLaMa 3.2 1B Instruct]
 27%|██▋       | 21/77 [00:30<01:13,  1.32s/it, LLaMa 3.2 1B Instruct]
 29%|██▊       | 22/77 [00:31<01:12,  1.31s/it, LLaMa 3.2 1B Instruct]
 30%|██▉       | 23/77 [00:33<01:10,  1.31s/it, LLaMa 3.2 1B Instruct]
 31%|███       | 24/77 [00:34<01:08,  1.29s/it, LLaMa 3.2 1B Instruct]
 32%|███▏      | 25/77 [00:35<01:07,  1.30s/it, LLaMa 3.2 1B Instruct]
 34%|███▍      | 26/77 [00:37<01:06,  1.31s/it, LLaMa 3.2 1B Instruct]
 35%|███▌      | 27/77 [00:38<01:05,  1.32s/it, LLaMa 3.2 1B Instruct]
 36%|███▋      | 28/77 [00:39<01:03,  1.30s/it, LLaMa 3.2 1B Instruct]
 38%|███▊      | 29/77 [00:41<01:02,  1.31s/it, LLaMa 3.2 1B Instruct]
 39%|███▉      | 30/77 [00:42<01:00,  1.29s/it, LLaMa 3.2 1B Instruct]
 40%|████      | 31/77 [00:43<00:59,  1.29s/it, LLaMa 3.2 1B Instruct]
 42%|████▏     | 32/77 [00:44<00:58,  1.31s/it, LLaMa 3.2 1B Instruct]
 43%|████▎     | 33/77 [00:46<00:57,  1.31s/it, LLaMa 3.2 1B Instruct]
 44%|████▍     | 34/77 [00:47<00:56,  1.32s/it, LLaMa 3.2 1B Instruct]
 45%|████▌     | 35/77 [00:48<00:54,  1.29s/it, LLaMa 3.2 1B Instruct]
 47%|████▋     | 36/77 [00:50<00:52,  1.28s/it, LLaMa 3.2 1B Instruct]
 48%|████▊     | 37/77 [00:51<00:51,  1.29s/it, LLaMa 3.2 1B Instruct]
 49%|████▉     | 38/77 [00:52<00:51,  1.32s/it, LLaMa 3.2 1B Instruct]
 51%|█████     | 39/77 [00:53<00:49,  1.30s/it, LLaMa 3.2 1B Instruct]
 52%|█████▏    | 40/77 [00:55<00:47,  1.28s/it, LLaMa 3.2 1B Instruct]
 53%|█████▎    | 41/77 [00:56<00:45,  1.27s/it, LLaMa 3.2 1B Instruct]
 55%|█████▍    | 42/77 [00:57<00:45,  1.29s/it, LLaMa 3.2 1B Instruct]
 56%|█████▌    | 43/77 [00:59<00:43,  1.28s/it, LLaMa 3.2 1B Instruct]
 57%|█████▋    | 44/77 [01:00<00:42,  1.29s/it, LLaMa 3.2 1B Instruct]
 58%|█████▊    | 45/77 [01:01<00:41,  1.30s/it, LLaMa 3.2 1B Instruct]
 60%|█████▉    | 46/77 [01:02<00:39,  1.28s/it, LLaMa 3.2 1B Instruct]
 61%|██████    | 47/77 [01:04<00:38,  1.29s/it, LLaMa 3.2 1B Instruct]
 62%|██████▏   | 48/77 [01:05<00:37,  1.30s/it, LLaMa 3.2 1B Instruct]
 64%|██████▎   | 49/77 [01:06<00:36,  1.30s/it, LLaMa 3.2 1B Instruct]
 65%|██████▍   | 50/77 [01:08<00:35,  1.31s/it, LLaMa 3.2 1B Instruct]
 66%|██████▌   | 51/77 [01:09<00:33,  1.29s/it, LLaMa 3.2 1B Instruct]
 68%|██████▊   | 52/77 [01:10<00:32,  1.30s/it, LLaMa 3.2 1B Instruct]
 69%|██████▉   | 53/77 [01:12<00:31,  1.30s/it, LLaMa 3.2 1B Instruct]
 70%|███████   | 54/77 [01:13<00:29,  1.30s/it, LLaMa 3.2 1B Instruct]
 71%|███████▏  | 55/77 [01:14<00:28,  1.31s/it, LLaMa 3.2 1B Instruct]
 73%|███████▎  | 56/77 [01:15<00:27,  1.31s/it, LLaMa 3.2 1B Instruct]
 74%|███████▍  | 57/77 [01:17<00:25,  1.29s/it, LLaMa 3.2 1B Instruct]
 75%|███████▌  | 58/77 [01:18<00:24,  1.29s/it, LLaMa 3.2 1B Instruct]
 77%|███████▋  | 59/77 [01:19<00:23,  1.30s/it, LLaMa 3.2 1B Instruct]
 78%|███████▊  | 60/77 [01:21<00:22,  1.31s/it, LLaMa 3.2 1B Instruct]
 79%|███████▉  | 61/77 [01:22<00:20,  1.29s/it, LLaMa 3.2 1B Instruct]
 81%|████████  | 62/77 [01:23<00:19,  1.29s/it, LLaMa 3.2 1B Instruct]
 82%|████████▏ | 63/77 [01:25<00:18,  1.30s/it, LLaMa 3.2 1B Instruct]
 83%|████████▎ | 64/77 [01:26<00:17,  1.33s/it, LLaMa 3.2 1B Instruct]
 84%|████████▍ | 65/77 [01:27<00:15,  1.32s/it, LLaMa 3.2 1B Instruct]
 86%|████████▌ | 66/77 [01:28<00:14,  1.30s/it, LLaMa 3.2 1B Instruct]
 87%|████████▋ | 67/77 [01:30<00:13,  1.32s/it, LLaMa 3.2 1B Instruct]
 88%|████████▊ | 68/77 [01:31<00:12,  1.34s/it, LLaMa 3.2 1B Instruct]
 90%|████████▉ | 69/77 [01:33<00:10,  1.33s/it, LLaMa 3.2 1B Instruct]
 91%|█████████ | 70/77 [01:34<00:09,  1.32s/it, LLaMa 3.2 1B Instruct]
 92%|█████████▏| 71/77 [01:35<00:07,  1.33s/it, LLaMa 3.2 1B Instruct]
 94%|█████████▎| 72/77 [01:36<00:06,  1.30s/it, LLaMa 3.2 1B Instruct]
 95%|█████████▍| 73/77 [01:38<00:05,  1.30s/it, LLaMa 3.2 1B Instruct]
 96%|█████████▌| 74/77 [01:39<00:03,  1.28s/it, LLaMa 3.2 1B Instruct]
 97%|█████████▋| 75/77 [01:40<00:02,  1.30s/it, LLaMa 3.2 1B Instruct]
 99%|█████████▊| 76/77 [01:42<00:01,  1.29s/it, LLaMa 3.2 1B Instruct]
