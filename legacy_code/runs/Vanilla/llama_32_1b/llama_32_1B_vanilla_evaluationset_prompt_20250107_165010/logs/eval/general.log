2025-01-07 16:50:14,040 INFO     Loading settings and stats
2025-01-07 16:50:14,040 INFO     Using prompt: Read the following Metal-Organic Framework (MOF) synthesis description and extract this information: temperature (highest reaction temp, use 25°C if not specified), time (longest duration at highest temp), one main solvent (no mixtures or ratios), one chemical additive ('None' if no additive present). Important: Do not use JSON or curly braces in your output, they are already provided for you and you do not need to generate them. Only output the extracted information and terminate strings with ", temperature: 0.1
2025-01-07 16:50:14,043 DEBUG    Settings loaded. CSV path: /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/tobias/SynMOF_M_out.csv
2025-01-07 16:50:14,043 WARNING  [Errno 2] No such file or directory: 'stats_llama_32_1B_vanilla_evaluationset_prompt_20250107_165010.yml'
2025-01-07 16:50:14,043 WARNING  [Errno 2] No such file or directory: 'stats_llama_32_1B_vanilla_evaluationset_prompt_20250107_165010.yaml'
2025-01-07 16:50:14,043 WARNING  Could not load 'stats_llama_32_1B_vanilla_evaluationset_prompt_20250107_165010.yml', creating it (empty)
2025-01-07 16:50:14,044 INFO     Loading labels from CSV file: /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/tobias/SynMOF_M_out.csv
2025-01-07 16:50:14,049 INFO     Found 778 paragraphs with labels
2025-01-07 16:50:14,050 DEBUG    First few valid IDs: ['SUKMAO_clean', 'QUNWAZ_clean', 'ZUDRAT_clean', 'LOXBEH_clean', 'BEDYEQ_clean']
2025-01-07 16:50:14,050 INFO     Loading evaluation set instead of regular dataset.
2025-01-07 16:50:14,050 DEBUG    Already evaluated: 0 items
2025-01-07 16:50:14,050 INFO     Loading Dataset from /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/eval_paragraphs
2025-01-07 16:50:14,050 INFO     Loading MOFDataset from '/gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/eval_paragraphs'
2025-01-07 16:50:14,055 INFO     Dataset loaded with 77 items
2025-01-07 16:50:14,055 INFO     Found 77 paragraphs that have labels in dataset
2025-01-07 16:50:14,055 DEBUG    First few overlapping IDs: ['KIVSUF_clean', 'VEMDAT_clean', 'YUGLES_clean', 'ILAGUY_charged', 'AVETEC_clean']
2025-01-07 16:50:14,055 INFO     Processing model: LLaMa 3.2 1B Instruct
2025-01-07 16:50:14,056 INFO       0%|          | 0/77 [00:00<?, ?it/s, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:14,056 INFO     Loading Model [LLaMa 3.2 1B Instruct] from /home/iti/zn2950/home/haicore_ws/base_models/Llama-3.2-1B-Instruct
2025-01-07 16:50:14,677 INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-01-07 16:50:18,673 INFO       1%|▏         | 1/77 [00:04<05:50,  4.62s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:19,983 INFO       3%|▎         | 2/77 [00:05<03:20,  2.67s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:21,222 INFO       4%|▍         | 3/77 [00:07<02:29,  2.02s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:22,448 INFO       5%|▌         | 4/77 [00:08<02:04,  1.70s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:23,694 INFO       6%|▋         | 5/77 [00:09<01:50,  1.54s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:24,918 INFO       8%|▊         | 6/77 [00:10<01:41,  1.43s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:26,146 INFO       9%|▉         | 7/77 [00:12<01:35,  1.37s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:27,365 INFO      10%|█         | 8/77 [00:13<01:31,  1.32s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:28,588 INFO      12%|█▏        | 9/77 [00:14<01:27,  1.29s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:29,802 INFO      13%|█▎        | 10/77 [00:15<01:24,  1.27s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:31,076 INFO      14%|█▍        | 11/77 [00:17<01:23,  1.27s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:32,272 INFO      16%|█▌        | 12/77 [00:18<01:21,  1.25s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:33,529 INFO      17%|█▋        | 13/77 [00:19<01:19,  1.25s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:34,769 INFO      18%|█▊        | 14/77 [00:20<01:18,  1.25s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:35,995 INFO      19%|█▉        | 15/77 [00:21<01:16,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:37,215 INFO      21%|██        | 16/77 [00:23<01:15,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:38,418 INFO      22%|██▏       | 17/77 [00:24<01:13,  1.22s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:39,636 INFO      23%|██▎       | 18/77 [00:25<01:12,  1.22s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:40,861 INFO      25%|██▍       | 19/77 [00:26<01:10,  1.22s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:42,101 INFO     Saving progress to `stats_llama_32_1B_vanilla_evaluationset_prompt_20250107_165010.yml`
2025-01-07 16:50:42,125 INFO      26%|██▌       | 20/77 [00:28<01:10,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:43,328 INFO      27%|██▋       | 21/77 [00:29<01:08,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:44,555 INFO      29%|██▊       | 22/77 [00:30<01:07,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:45,863 INFO      30%|██▉       | 23/77 [00:31<01:07,  1.25s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:47,070 INFO      31%|███       | 24/77 [00:33<01:05,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:48,345 INFO      32%|███▏      | 25/77 [00:34<01:04,  1.25s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:49,576 INFO      34%|███▍      | 26/77 [00:35<01:03,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:50,850 INFO      35%|███▌      | 27/77 [00:36<01:02,  1.25s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:52,080 INFO      36%|███▋      | 28/77 [00:38<01:01,  1.25s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:53,293 INFO      38%|███▊      | 29/77 [00:39<00:59,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:54,526 INFO      39%|███▉      | 30/77 [00:40<00:58,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:55,788 INFO      40%|████      | 31/77 [00:41<00:57,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:57,025 INFO      42%|████▏     | 32/77 [00:42<00:55,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:58,266 INFO      43%|████▎     | 33/77 [00:44<00:54,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:50:59,483 INFO      44%|████▍     | 34/77 [00:45<00:53,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:00,700 INFO      45%|████▌     | 35/77 [00:46<00:51,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:01,931 INFO      47%|████▋     | 36/77 [00:47<00:50,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:03,211 INFO      48%|████▊     | 37/77 [00:49<00:49,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:04,524 INFO      49%|████▉     | 38/77 [00:50<00:49,  1.27s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:05,749 INFO      51%|█████     | 39/77 [00:51<00:47,  1.25s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:06,958 INFO     Saving progress to `stats_llama_32_1B_vanilla_evaluationset_prompt_20250107_165010.yml`
2025-01-07 16:51:06,988 INFO      52%|█████▏    | 40/77 [00:52<00:46,  1.25s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:08,192 INFO      53%|█████▎    | 41/77 [00:54<00:44,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:09,416 INFO      55%|█████▍    | 42/77 [00:55<00:43,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:10,667 INFO      56%|█████▌    | 43/77 [00:56<00:42,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:11,965 INFO      57%|█████▋    | 44/77 [00:57<00:41,  1.26s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:13,249 INFO      58%|█████▊    | 45/77 [00:59<00:40,  1.26s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:14,481 INFO      60%|█████▉    | 46/77 [01:00<00:38,  1.25s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:15,678 INFO      61%|██████    | 47/77 [01:01<00:37,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:16,915 INFO      62%|██████▏   | 48/77 [01:02<00:35,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:18,130 INFO      64%|██████▎   | 49/77 [01:04<00:34,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:19,438 INFO      65%|██████▍   | 50/77 [01:05<00:33,  1.25s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:20,639 INFO      66%|██████▌   | 51/77 [01:06<00:32,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:21,862 INFO      68%|██████▊   | 52/77 [01:07<00:30,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:23,080 INFO      69%|██████▉   | 53/77 [01:09<00:29,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:24,302 INFO      70%|███████   | 54/77 [01:10<00:28,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:25,521 INFO      71%|███████▏  | 55/77 [01:11<00:26,  1.22s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:26,736 INFO      73%|███████▎  | 56/77 [01:12<00:25,  1.22s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:27,940 INFO      74%|███████▍  | 57/77 [01:13<00:24,  1.22s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:29,151 INFO      75%|███████▌  | 58/77 [01:15<00:23,  1.21s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:30,364 INFO      77%|███████▋  | 59/77 [01:16<00:21,  1.21s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:31,607 INFO     Saving progress to `stats_llama_32_1B_vanilla_evaluationset_prompt_20250107_165010.yml`
2025-01-07 16:51:31,642 INFO      78%|███████▊  | 60/77 [01:17<00:20,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:32,861 INFO      79%|███████▉  | 61/77 [01:18<00:19,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:34,083 INFO      81%|████████  | 62/77 [01:20<00:18,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:35,311 INFO      82%|████████▏ | 63/77 [01:21<00:17,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:36,626 INFO      83%|████████▎ | 64/77 [01:22<00:16,  1.25s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:37,862 INFO      84%|████████▍ | 65/77 [01:23<00:14,  1.25s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:39,080 INFO      86%|████████▌ | 66/77 [01:25<00:13,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:40,355 INFO      87%|████████▋ | 67/77 [01:26<00:12,  1.25s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:41,624 INFO      88%|████████▊ | 68/77 [01:27<00:11,  1.26s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:42,823 INFO      90%|████████▉ | 69/77 [01:28<00:09,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:44,063 INFO      91%|█████████ | 70/77 [01:30<00:08,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:45,313 INFO      92%|█████████▏| 71/77 [01:31<00:07,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:46,532 INFO      94%|█████████▎| 72/77 [01:32<00:06,  1.24s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:47,741 INFO      95%|█████████▍| 73/77 [01:33<00:04,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:48,972 INFO      96%|█████████▌| 74/77 [01:34<00:03,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:50,214 INFO      97%|█████████▋| 75/77 [01:36<00:02,  1.23s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:51,495 INFO      99%|█████████▊| 76/77 [01:37<00:01,  1.25s/it, LLaMa 3.2 1B Instruct]
2025-01-07 16:51:52,713 INFO     Saving progress to `stats_llama_32_1B_vanilla_evaluationset_prompt_20250107_165010.yml`
2025-01-07 16:51:52,756 INFO     Processing model: LLaMa 3.2 3B Instruct
2025-01-07 16:51:52,756 INFO     Skipping model [LLaMa 3.2 3B Instruct]
