2025-01-06 11:42:43,858 INFO     Loading settings and stats
2025-01-06 11:42:43,858 INFO     Using prompt: , temperature: 0.1
2025-01-06 11:42:43,861 DEBUG    Settings loaded. CSV path: /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/tobias/SynMOF_M_out.csv
2025-01-06 11:42:43,861 WARNING  [Errno 2] No such file or directory: 'stats_llama_31_instruction_full_ft_epoch_3_20250106_114240.yml'
2025-01-06 11:42:43,861 WARNING  [Errno 2] No such file or directory: 'stats_llama_31_instruction_full_ft_epoch_3_20250106_114240.yaml'
2025-01-06 11:42:43,861 WARNING  Could not load 'stats_llama_31_instruction_full_ft_epoch_3_20250106_114240.yml', creating it (empty)
2025-01-06 11:42:43,862 INFO     Loading labels from CSV file: /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/tobias/SynMOF_M_out.csv
2025-01-06 11:42:43,867 INFO     Found 778 paragraphs with labels
2025-01-06 11:42:43,867 DEBUG    First few valid IDs: ['BOPHIZ_clean', 'HUVHOX_clean', 'QIYBUX_clean', 'QAWPIO_clean', 'XAXQEU_SL']
2025-01-06 11:42:43,867 INFO     Loading evaluation set instead of regular dataset.
2025-01-06 11:42:43,867 DEBUG    Already evaluated: 0 items
2025-01-06 11:42:43,867 INFO     Loading Dataset from /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/eval_paragraphs
2025-01-06 11:42:43,867 INFO     Loading MOFDataset from '/gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/eval_paragraphs'
2025-01-06 11:42:43,871 INFO     Dataset loaded with 77 items
2025-01-06 11:42:43,871 INFO     Found 77 paragraphs that have labels in dataset
2025-01-06 11:42:43,871 DEBUG    First few overlapping IDs: ['BOPHIZ_clean', 'NORJEL_clean', 'HUVHIR_clean', 'ELOZIQ_clean', 'LUCKAX_clean']
2025-01-06 11:42:43,871 INFO     Processing model: LLaMa 3.1 8B
2025-01-06 11:42:43,871 INFO     Skipping model [LLaMa 3.1 8B]
2025-01-06 11:42:43,871 INFO     Processing model: LLaMa 3.1 8B Instruct
2025-01-06 11:42:43,872 INFO       0%|          | 0/77 [00:00<?, ?it/s, LLaMa 3.1 8B Instruct]
2025-01-06 11:42:43,873 INFO     Loading Model [LLaMa 3.1 8B Instruct] from /home/iti/zn2950/home/haicore_ws/tunes/llama31_8b/instruction_full_ft/run_1_1736114112/epoch_3
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
/home/iti/zn2950/miniconda3/envs/llm-extraction/lib/python3.11/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/iti/zn2950/miniconda3/envs/llm-extraction did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...
  warn(msg)
2025-01-06 11:42:44,911 INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
  0%|          | 0/77 [00:00<?, ?it/s, LLaMa 3.1 8B Instruct]

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /home/iti/zn2950/miniconda3/envs/llm-extraction/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cuda118.so
CUDA SETUP: CUDA runtime path found: /software/all/devel/cuda/11.8/lib64/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.0
CUDA SETUP: Detected CUDA version 118
CUDA SETUP: Loading binary /home/iti/zn2950/miniconda3/envs/llm-extraction/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][A
Loading checkpoint shards:  25%|██▌       | 1/4 [00:07<00:21,  7.13s/it][A
Loading checkpoint shards:  50%|█████     | 2/4 [00:14<00:14,  7.23s/it][A
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:21<00:07,  7.22s/it][A
Loading checkpoint shards: 100%|██████████| 4/4 [00:23<00:00,  5.06s/it][ALoading checkpoint shards: 100%|██████████| 4/4 [00:23<00:00,  5.85s/it]
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
2025-01-06 11:43:13,125 INFO       1%|▏         | 1/77 [00:29<37:03, 29.25s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:43:16,909 INFO       3%|▎         | 2/77 [00:33<17:50, 14.27s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:43:22,558 INFO       4%|▍         | 3/77 [00:38<12:44, 10.33s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:43:25,837 INFO       5%|▌         | 4/77 [00:41<09:11,  7.55s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:43:31,103 INFO       6%|▋         | 5/77 [00:47<08:04,  6.73s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:43:35,232 INFO       8%|▊         | 6/77 [00:51<06:54,  5.84s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:43:38,733 INFO       9%|▉         | 7/77 [00:54<05:55,  5.08s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:43:44,045 INFO      10%|█         | 8/77 [01:00<05:55,  5.15s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:43:49,201 INFO      12%|█▏        | 9/77 [01:05<05:50,  5.15s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:43:54,606 INFO      13%|█▎        | 10/77 [01:10<05:50,  5.23s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:43:58,896 INFO      14%|█▍        | 11/77 [01:15<05:26,  4.94s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:44:02,351 INFO      16%|█▌        | 12/77 [01:18<04:51,  4.49s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:44:05,518 INFO      17%|█▋        | 13/77 [01:21<04:21,  4.09s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:44:08,640 INFO      18%|█▊        | 14/77 [01:24<03:59,  3.80s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:44:11,766 INFO      19%|█▉        | 15/77 [01:27<03:42,  3.59s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:44:16,798 INFO      21%|██        | 16/77 [01:32<04:05,  4.03s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:44:20,218 INFO      22%|██▏       | 17/77 [01:36<03:50,  3.84s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:44:23,495 INFO      23%|██▎       | 18/77 [01:39<03:36,  3.67s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:44:28,807 INFO      25%|██▍       | 19/77 [01:44<04:01,  4.17s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:44:32,032 INFO     Saving progress to `stats_llama_31_instruction_full_ft_epoch_3_20250106_114240.yml`
2025-01-06 11:44:32,044 INFO      26%|██▌       | 20/77 [01:48<03:41,  3.89s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:44:36,393 INFO      27%|██▋       | 21/77 [01:52<03:45,  4.03s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:44:40,533 INFO      29%|██▊       | 22/77 [01:56<03:43,  4.06s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:44:46,020 INFO      30%|██▉       | 23/77 [02:02<04:02,  4.49s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:44:49,323 INFO      31%|███       | 24/77 [02:05<03:39,  4.13s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:44:55,833 INFO      32%|███▏      | 25/77 [02:11<04:11,  4.85s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:44:59,148 INFO      34%|███▍      | 26/77 [02:15<03:43,  4.39s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:45:02,311 INFO      35%|███▌      | 27/77 [02:18<03:20,  4.02s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:45:07,687 INFO      36%|███▋      | 28/77 [02:23<03:36,  4.43s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:45:12,026 INFO      38%|███▊      | 29/77 [02:28<03:31,  4.40s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:45:15,915 INFO      39%|███▉      | 30/77 [02:32<03:19,  4.25s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:45:19,071 INFO      40%|████      | 31/77 [02:35<03:00,  3.92s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:45:26,227 INFO      42%|████▏     | 32/77 [02:42<03:40,  4.89s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:45:29,756 INFO      43%|████▎     | 33/77 [02:45<03:17,  4.48s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:45:33,123 INFO      44%|████▍     | 34/77 [02:49<02:58,  4.15s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:45:36,300 INFO      45%|████▌     | 35/77 [02:52<02:41,  3.86s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:45:39,623 INFO      47%|████▋     | 36/77 [02:55<02:31,  3.70s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:45:42,932 INFO      48%|████▊     | 37/77 [02:59<02:23,  3.58s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:45:46,388 INFO      49%|████▉     | 38/77 [03:02<02:18,  3.54s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:45:49,585 INFO      51%|█████     | 39/77 [03:05<02:10,  3.44s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:45:53,821 INFO     Saving progress to `stats_llama_31_instruction_full_ft_epoch_3_20250106_114240.yml`
2025-01-06 11:45:53,848 INFO      52%|█████▏    | 40/77 [03:09<02:16,  3.69s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:45:57,307 INFO      53%|█████▎    | 41/77 [03:13<02:10,  3.62s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:46:00,759 INFO      55%|█████▍    | 42/77 [03:16<02:04,  3.57s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:46:05,040 INFO      56%|█████▌    | 43/77 [03:21<02:08,  3.78s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:46:10,419 INFO      57%|█████▋    | 44/77 [03:26<02:20,  4.26s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:46:13,742 INFO      58%|█████▊    | 45/77 [03:29<02:07,  3.98s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:46:20,092 INFO      60%|█████▉    | 46/77 [03:36<02:25,  4.69s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:46:27,556 INFO      61%|██████    | 47/77 [03:43<02:45,  5.52s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:46:33,056 INFO      62%|██████▏   | 48/77 [03:49<02:39,  5.52s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:46:36,301 INFO      64%|██████▎   | 49/77 [03:52<02:15,  4.83s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:46:41,098 INFO      65%|██████▍   | 50/77 [03:57<02:10,  4.82s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:46:46,039 INFO      66%|██████▌   | 51/77 [04:02<02:06,  4.86s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:46:49,240 INFO      68%|██████▊   | 52/77 [04:05<01:49,  4.36s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:46:53,539 INFO      69%|██████▉   | 53/77 [04:09<01:44,  4.34s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:46:59,868 INFO      70%|███████   | 54/77 [04:15<01:53,  4.94s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:47:05,521 INFO      71%|███████▏  | 55/77 [04:21<01:53,  5.15s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:47:09,251 INFO      73%|███████▎  | 56/77 [04:25<01:39,  4.73s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:47:13,974 INFO      74%|███████▍  | 57/77 [04:30<01:34,  4.73s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:47:21,253 INFO      75%|███████▌  | 58/77 [04:37<01:44,  5.49s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:47:28,445 INFO      77%|███████▋  | 59/77 [04:44<01:48,  6.00s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:47:33,222 INFO     Saving progress to `stats_llama_31_instruction_full_ft_epoch_3_20250106_114240.yml`
2025-01-06 11:47:33,258 INFO      78%|███████▊  | 60/77 [04:49<01:35,  5.64s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:47:37,468 INFO      79%|███████▉  | 61/77 [04:53<01:23,  5.21s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:47:40,717 INFO      81%|████████  | 62/77 [04:56<01:09,  4.62s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:47:44,050 INFO      82%|████████▏ | 63/77 [05:00<00:59,  4.24s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:47:48,222 INFO      83%|████████▎ | 64/77 [05:04<00:54,  4.22s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:47:53,788 INFO      84%|████████▍ | 65/77 [05:09<00:55,  4.62s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:47:56,971 INFO      86%|████████▌ | 66/77 [05:13<00:46,  4.19s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:48:00,344 INFO      87%|████████▋ | 67/77 [05:16<00:39,  3.95s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:48:05,583 INFO      88%|████████▊ | 68/77 [05:21<00:38,  4.33s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:48:09,825 INFO      90%|████████▉ | 69/77 [05:25<00:34,  4.31s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:48:13,027 INFO      91%|█████████ | 70/77 [05:29<00:27,  3.97s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:48:16,366 INFO      92%|█████████▏| 71/77 [05:32<00:22,  3.78s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:48:21,775 INFO      94%|█████████▎| 72/77 [05:37<00:21,  4.27s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:48:25,101 INFO      95%|█████████▍| 73/77 [05:41<00:15,  3.99s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:48:29,393 INFO      96%|█████████▌| 74/77 [05:45<00:12,  4.08s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:48:33,612 INFO      97%|█████████▋| 75/77 [05:49<00:08,  4.12s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:48:37,918 INFO      99%|█████████▊| 76/77 [05:54<00:04,  4.18s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:48:41,286 INFO     Saving progress to `stats_llama_31_instruction_full_ft_epoch_3_20250106_114240.yml`
  1%|▏         | 1/77 [00:29<37:03, 29.25s/it, LLaMa 3.1 8B Instruct]
  3%|▎         | 2/77 [00:33<17:50, 14.27s/it, LLaMa 3.1 8B Instruct]
  4%|▍         | 3/77 [00:38<12:44, 10.33s/it, LLaMa 3.1 8B Instruct]
  5%|▌         | 4/77 [00:41<09:11,  7.55s/it, LLaMa 3.1 8B Instruct]
  6%|▋         | 5/77 [00:47<08:04,  6.73s/it, LLaMa 3.1 8B Instruct]
  8%|▊         | 6/77 [00:51<06:54,  5.84s/it, LLaMa 3.1 8B Instruct]
  9%|▉         | 7/77 [00:54<05:55,  5.08s/it, LLaMa 3.1 8B Instruct]
 10%|█         | 8/77 [01:00<05:55,  5.15s/it, LLaMa 3.1 8B Instruct]
 12%|█▏        | 9/77 [01:05<05:50,  5.15s/it, LLaMa 3.1 8B Instruct]
 13%|█▎        | 10/77 [01:10<05:50,  5.23s/it, LLaMa 3.1 8B Instruct]
 14%|█▍        | 11/77 [01:15<05:26,  4.94s/it, LLaMa 3.1 8B Instruct]
 16%|█▌        | 12/77 [01:18<04:51,  4.49s/it, LLaMa 3.1 8B Instruct]
 17%|█▋        | 13/77 [01:21<04:21,  4.09s/it, LLaMa 3.1 8B Instruct]
 18%|█▊        | 14/77 [01:24<03:59,  3.80s/it, LLaMa 3.1 8B Instruct]
 19%|█▉        | 15/77 [01:27<03:42,  3.59s/it, LLaMa 3.1 8B Instruct]
 21%|██        | 16/77 [01:32<04:05,  4.03s/it, LLaMa 3.1 8B Instruct]
 22%|██▏       | 17/77 [01:36<03:50,  3.84s/it, LLaMa 3.1 8B Instruct]
 23%|██▎       | 18/77 [01:39<03:36,  3.67s/it, LLaMa 3.1 8B Instruct]
 25%|██▍       | 19/77 [01:44<04:01,  4.17s/it, LLaMa 3.1 8B Instruct]
 26%|██▌       | 20/77 [01:48<03:41,  3.89s/it, LLaMa 3.1 8B Instruct]
 27%|██▋       | 21/77 [01:52<03:45,  4.03s/it, LLaMa 3.1 8B Instruct]
 29%|██▊       | 22/77 [01:56<03:43,  4.06s/it, LLaMa 3.1 8B Instruct]
 30%|██▉       | 23/77 [02:02<04:02,  4.49s/it, LLaMa 3.1 8B Instruct]
 31%|███       | 24/77 [02:05<03:39,  4.13s/it, LLaMa 3.1 8B Instruct]
 32%|███▏      | 25/77 [02:11<04:11,  4.85s/it, LLaMa 3.1 8B Instruct]
 34%|███▍      | 26/77 [02:15<03:43,  4.39s/it, LLaMa 3.1 8B Instruct]
 35%|███▌      | 27/77 [02:18<03:20,  4.02s/it, LLaMa 3.1 8B Instruct]
 36%|███▋      | 28/77 [02:23<03:36,  4.43s/it, LLaMa 3.1 8B Instruct]
 38%|███▊      | 29/77 [02:28<03:31,  4.40s/it, LLaMa 3.1 8B Instruct]
 39%|███▉      | 30/77 [02:32<03:19,  4.25s/it, LLaMa 3.1 8B Instruct]
 40%|████      | 31/77 [02:35<03:00,  3.92s/it, LLaMa 3.1 8B Instruct]
 42%|████▏     | 32/77 [02:42<03:40,  4.89s/it, LLaMa 3.1 8B Instruct]
 43%|████▎     | 33/77 [02:45<03:17,  4.48s/it, LLaMa 3.1 8B Instruct]
 44%|████▍     | 34/77 [02:49<02:58,  4.15s/it, LLaMa 3.1 8B Instruct]
 45%|████▌     | 35/77 [02:52<02:41,  3.86s/it, LLaMa 3.1 8B Instruct]
 47%|████▋     | 36/77 [02:55<02:31,  3.70s/it, LLaMa 3.1 8B Instruct]
 48%|████▊     | 37/77 [02:59<02:23,  3.58s/it, LLaMa 3.1 8B Instruct]
 49%|████▉     | 38/77 [03:02<02:18,  3.54s/it, LLaMa 3.1 8B Instruct]
 51%|█████     | 39/77 [03:05<02:10,  3.44s/it, LLaMa 3.1 8B Instruct]
 52%|█████▏    | 40/77 [03:09<02:16,  3.69s/it, LLaMa 3.1 8B Instruct]
 53%|█████▎    | 41/77 [03:13<02:10,  3.62s/it, LLaMa 3.1 8B Instruct]
 55%|█████▍    | 42/77 [03:16<02:04,  3.57s/it, LLaMa 3.1 8B Instruct]
 56%|█████▌    | 43/77 [03:21<02:08,  3.78s/it, LLaMa 3.1 8B Instruct]
 57%|█████▋    | 44/77 [03:26<02:20,  4.26s/it, LLaMa 3.1 8B Instruct]
 58%|█████▊    | 45/77 [03:29<02:07,  3.98s/it, LLaMa 3.1 8B Instruct]
 60%|█████▉    | 46/77 [03:36<02:25,  4.69s/it, LLaMa 3.1 8B Instruct]
 61%|██████    | 47/77 [03:43<02:45,  5.52s/it, LLaMa 3.1 8B Instruct]
 62%|██████▏   | 48/77 [03:49<02:39,  5.52s/it, LLaMa 3.1 8B Instruct]
 64%|██████▎   | 49/77 [03:52<02:15,  4.83s/it, LLaMa 3.1 8B Instruct]
 65%|██████▍   | 50/77 [03:57<02:10,  4.82s/it, LLaMa 3.1 8B Instruct]
 66%|██████▌   | 51/77 [04:02<02:06,  4.86s/it, LLaMa 3.1 8B Instruct]
 68%|██████▊   | 52/77 [04:05<01:49,  4.36s/it, LLaMa 3.1 8B Instruct]
 69%|██████▉   | 53/77 [04:09<01:44,  4.34s/it, LLaMa 3.1 8B Instruct]
 70%|███████   | 54/77 [04:15<01:53,  4.94s/it, LLaMa 3.1 8B Instruct]
 71%|███████▏  | 55/77 [04:21<01:53,  5.15s/it, LLaMa 3.1 8B Instruct]
 73%|███████▎  | 56/77 [04:25<01:39,  4.73s/it, LLaMa 3.1 8B Instruct]
 74%|███████▍  | 57/77 [04:30<01:34,  4.73s/it, LLaMa 3.1 8B Instruct]
 75%|███████▌  | 58/77 [04:37<01:44,  5.49s/it, LLaMa 3.1 8B Instruct]
 77%|███████▋  | 59/77 [04:44<01:48,  6.00s/it, LLaMa 3.1 8B Instruct]
 78%|███████▊  | 60/77 [04:49<01:35,  5.64s/it, LLaMa 3.1 8B Instruct]
 79%|███████▉  | 61/77 [04:53<01:23,  5.21s/it, LLaMa 3.1 8B Instruct]
 81%|████████  | 62/77 [04:56<01:09,  4.62s/it, LLaMa 3.1 8B Instruct]
 82%|████████▏ | 63/77 [05:00<00:59,  4.24s/it, LLaMa 3.1 8B Instruct]
 83%|████████▎ | 64/77 [05:04<00:54,  4.22s/it, LLaMa 3.1 8B Instruct]
 84%|████████▍ | 65/77 [05:09<00:55,  4.62s/it, LLaMa 3.1 8B Instruct]
 86%|████████▌ | 66/77 [05:13<00:46,  4.19s/it, LLaMa 3.1 8B Instruct]
 87%|████████▋ | 67/77 [05:16<00:39,  3.95s/it, LLaMa 3.1 8B Instruct]
 88%|████████▊ | 68/77 [05:21<00:38,  4.33s/it, LLaMa 3.1 8B Instruct]
 90%|████████▉ | 69/77 [05:25<00:34,  4.31s/it, LLaMa 3.1 8B Instruct]
 91%|█████████ | 70/77 [05:29<00:27,  3.97s/it, LLaMa 3.1 8B Instruct]
 92%|█████████▏| 71/77 [05:32<00:22,  3.78s/it, LLaMa 3.1 8B Instruct]
 94%|█████████▎| 72/77 [05:37<00:21,  4.27s/it, LLaMa 3.1 8B Instruct]
 95%|█████████▍| 73/77 [05:41<00:15,  3.99s/it, LLaMa 3.1 8B Instruct]
 96%|█████████▌| 74/77 [05:45<00:12,  4.08s/it, LLaMa 3.1 8B Instruct]
 97%|█████████▋| 75/77 [05:49<00:08,  4.12s/it, LLaMa 3.1 8B Instruct]
 99%|█████████▊| 76/77 [05:54<00:04,  4.18s/it, LLaMa 3.1 8B Instruct]
