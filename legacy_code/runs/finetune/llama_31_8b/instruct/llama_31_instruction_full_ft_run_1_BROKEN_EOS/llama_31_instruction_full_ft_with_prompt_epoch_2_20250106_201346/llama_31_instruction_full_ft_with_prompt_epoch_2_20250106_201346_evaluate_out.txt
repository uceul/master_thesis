2025-01-06 20:13:50,587 INFO     Loading settings and stats
2025-01-06 20:13:50,587 INFO     Using prompt: Extract these synthesis conditions from the following Metal-Organic Framework (MOF) synthesis description: temperature (highest reaction temp, use 25Â°C if not specified), time (longest duration at highest temp), choose one main solvent (no mixtures or ratios), choose one chemical additive (write 'None' if no additive present). Never use JSON formatting like curly braces, escape characters, or newlines in your responses. Answers should be plain text values only., temperature: 0.0
2025-01-06 20:13:50,590 DEBUG    Settings loaded. CSV path: /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/tobias/SynMOF_M_out.csv
2025-01-06 20:13:50,590 WARNING  [Errno 2] No such file or directory: 'stats_llama_31_instruction_full_ft_with_prompt_epoch_2_20250106_201346.yml'
2025-01-06 20:13:50,590 WARNING  [Errno 2] No such file or directory: 'stats_llama_31_instruction_full_ft_with_prompt_epoch_2_20250106_201346.yaml'
2025-01-06 20:13:50,590 WARNING  Could not load 'stats_llama_31_instruction_full_ft_with_prompt_epoch_2_20250106_201346.yml', creating it (empty)
2025-01-06 20:13:50,592 INFO     Loading labels from CSV file: /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/tobias/SynMOF_M_out.csv
2025-01-06 20:13:50,597 INFO     Found 778 paragraphs with labels
2025-01-06 20:13:50,597 DEBUG    First few valid IDs: ['HUYXOP_clean', 'DACSAE_clean', 'LELROL_clean', 'NOBVOR_clean', 'PEKZIP_clean']
2025-01-06 20:13:50,597 INFO     Loading evaluation set instead of regular dataset.
2025-01-06 20:13:50,598 DEBUG    Already evaluated: 0 items
2025-01-06 20:13:50,598 INFO     Loading Dataset from /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/eval_paragraphs
2025-01-06 20:13:50,598 INFO     Loading MOFDataset from '/gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/eval_paragraphs'
2025-01-06 20:13:50,602 INFO     Dataset loaded with 77 items
2025-01-06 20:13:50,602 INFO     Found 77 paragraphs that have labels in dataset
2025-01-06 20:13:50,602 DEBUG    First few overlapping IDs: ['GUJREK_clean', 'ODEZAB_clean', 'AVETEC_clean', 'ACUJOZ_manual', 'TETZEZ_clean']
2025-01-06 20:13:50,602 INFO     Processing model: LLaMa 3.1 8B
2025-01-06 20:13:50,602 INFO     Skipping model [LLaMa 3.1 8B]
2025-01-06 20:13:50,602 INFO     Processing model: LLaMa 3.1 8B Instruct
2025-01-06 20:13:50,603 INFO       0%|          | 0/77 [00:00<?, ?it/s, LLaMa 3.1 8B Instruct]
2025-01-06 20:13:50,603 INFO     Loading Model [LLaMa 3.1 8B Instruct] from /home/iti/zn2950/home/haicore_ws/tunes/llama31_8b/instruction_full_ft/run_1_1736114112/epoch_2
2025-01-06 20:13:51,277 INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
  0%|          | 0/77 [00:00<?, ?it/s, LLaMa 3.1 8B Instruct]

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][A
Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:12,  4.16s/it][A
Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:08<00:08,  4.12s/it][A
Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:12<00:04,  4.09s/it][A
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:13<00:00,  2.89s/it][ALoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:13<00:00,  3.34s/it]
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/master_thesis/legacy_c â”‚
â”‚ ode/src/mthesis/main.py:284 in evaluate                              â”‚
â”‚                                                                      â”‚
â”‚   281 â”‚   â”‚   â”‚   â”‚   progress_bar.update(diff)                      â”‚
â”‚   282 â”‚   â”‚   â”‚   â”‚   first = False                                  â”‚
â”‚   283 â”‚   â”‚   â”‚   â”‚   log.info(f"Loading Model [{model_name}] from { â”‚
â”‚ â± 284 â”‚   â”‚   â”‚   â”‚   model = JsonformerModel(prompt=prompt, tempera â”‚
â”‚   285 â”‚   â”‚   â”‚   â”‚   model.eval()  # set model to eval mode         â”‚
â”‚   286 â”‚   â”‚   â”‚                                                      â”‚
â”‚   287 â”‚   â”‚   â”‚   count += 1                                         â”‚
â”‚                                                                      â”‚
â”‚ â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ locals â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® â”‚
â”‚ â”‚               batch = {                                          â”‚ â”‚
â”‚ â”‚                       â”‚   'paragraph_id': 'IQECIS_clean',        â”‚ â”‚
â”‚ â”‚                       â”‚   'text': 'CoSO4â‹…7 H2O (0.029 g, 0.103   â”‚ â”‚
â”‚ â”‚                       mmol), tpt (0.019 g, 0.061 mmol), and      â”‚ â”‚
â”‚ â”‚                       H3btb (0.021 g'+621                        â”‚ â”‚
â”‚ â”‚                       }                                          â”‚ â”‚
â”‚ â”‚               count = 0                                          â”‚ â”‚
â”‚ â”‚             dataset = <mthesis.dataloader.MOFDataset object at   â”‚ â”‚
â”‚ â”‚                       0x15390aea36d0>                            â”‚ â”‚
â”‚ â”‚         dataset_ids = {                                          â”‚ â”‚
â”‚ â”‚                       â”‚   'GUJREK_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'ODEZAB_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'AVETEC_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'ACUJOZ_manual',                       â”‚ â”‚
â”‚ â”‚                       â”‚   'TETZEZ_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'LAHTUM_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'VEMDAT_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'TEVHEJ_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'IPIHIA_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'DOKHOB_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   ... +67                                â”‚ â”‚
â”‚ â”‚                       }                                          â”‚ â”‚
â”‚ â”‚        dataset_path = '/gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn29â€¦ â”‚ â”‚
â”‚ â”‚         description = ''                                         â”‚ â”‚
â”‚ â”‚              device = device(type='cuda')                        â”‚ â”‚
â”‚ â”‚                diff = 0                                          â”‚ â”‚
â”‚ â”‚           evaluated = frozenset()                                â”‚ â”‚
â”‚ â”‚      evaluation_set = True                                       â”‚ â”‚
â”‚ â”‚               first = False                                      â”‚ â”‚
â”‚ â”‚           labels_df = â”‚    Unnamed: 0      filename DISORDER     â”‚ â”‚
â”‚ â”‚                       ... other6 other7  other8                  â”‚ â”‚
â”‚ â”‚                       0             0  OFODET_clean      NaN     â”‚ â”‚
â”‚ â”‚                       ...    NaN    NaN     NaN                  â”‚ â”‚
â”‚ â”‚                       1             1  XAVKIR_clean      NaN     â”‚ â”‚
â”‚ â”‚                       ...    NaN    NaN     NaN                  â”‚ â”‚
â”‚ â”‚                       2             3  LATPIG_clean      NaN     â”‚ â”‚
â”‚ â”‚                       ...    NaN    NaN     NaN                  â”‚ â”‚
â”‚ â”‚                       3             4  MOYYIJ_clean      NaN     â”‚ â”‚
â”‚ â”‚                       ...    NaN    NaN     NaN                  â”‚ â”‚
â”‚ â”‚                       4             5  OFOCUI_clean      NaN     â”‚ â”‚
â”‚ â”‚                       ...    NaN    NaN     NaN                  â”‚ â”‚
â”‚ â”‚                       ..          ...           ...      ...     â”‚ â”‚
â”‚ â”‚                       ...    ...    ...     ...                  â”‚ â”‚
â”‚ â”‚                       773         963  LEVDIB_clean      NaN     â”‚ â”‚
â”‚ â”‚                       ...    NaN    NaN     NaN                  â”‚ â”‚
â”‚ â”‚                       774         964  LIKDOA_clean      NaN     â”‚ â”‚
â”‚ â”‚                       ...    NaN    NaN     NaN                  â”‚ â”‚
â”‚ â”‚                       775         967  MUNDAC_clean      NaN     â”‚ â”‚
â”‚ â”‚                       ...    NaN    NaN     NaN                  â”‚ â”‚
â”‚ â”‚                       776         968  MUNDOQ_clean      NaN     â”‚ â”‚
â”‚ â”‚                       ...    NaN    NaN     NaN                  â”‚ â”‚
â”‚ â”‚                       777         970  OYIVIC_clean      NaN     â”‚ â”‚
â”‚ â”‚                       ...    NaN    NaN     NaN                  â”‚ â”‚
â”‚ â”‚                                                                  â”‚ â”‚
â”‚ â”‚                       [778 rows x 36 columns]                    â”‚ â”‚
â”‚ â”‚             log_dir = 'logs/llama_31_instruction_full_ft_with_pâ€¦ â”‚ â”‚
â”‚ â”‚          model_name = 'LLaMa 3.1 8B Instruct'                    â”‚ â”‚
â”‚ â”‚          model_path = '/home/iti/zn2950/home/haicore_ws/tunes/lâ€¦ â”‚ â”‚
â”‚ â”‚      model_settings = {                                          â”‚ â”‚
â”‚ â”‚                       â”‚   'model_name': 'LLaMa 3.1 8B Instruct', â”‚ â”‚
â”‚ â”‚                       â”‚   'model_path':                          â”‚ â”‚
â”‚ â”‚                       '/home/iti/zn2950/home/haicore_ws/tunes/lâ€¦ â”‚ â”‚
â”‚ â”‚                       â”‚   'model_type': 'text-generation'        â”‚ â”‚
â”‚ â”‚                       }                                          â”‚ â”‚
â”‚ â”‚          only_model = 'LLaMa 3.1 8B Instruct'                    â”‚ â”‚
â”‚ â”‚             overlap = {                                          â”‚ â”‚
â”‚ â”‚                       â”‚   'GUJREK_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'ODEZAB_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'AVETEC_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'ACUJOZ_manual',                       â”‚ â”‚
â”‚ â”‚                       â”‚   'TETZEZ_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'LAHTUM_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'VEMDAT_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'TEVHEJ_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'IPIHIA_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'DOKHOB_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   ... +67                                â”‚ â”‚
â”‚ â”‚                       }                                          â”‚ â”‚
â”‚ â”‚        paragraph_id = 'IQECIS_clean'                             â”‚ â”‚
â”‚ â”‚        progress_bar = <tqdm.std.tqdm object at 0x15390aec1d90>   â”‚ â”‚
â”‚ â”‚              prompt = 'Extract these synthesis conditions from   â”‚ â”‚
â”‚ â”‚                       the following Metal-Organic Framework      â”‚ â”‚
â”‚ â”‚                       (M'+385                                    â”‚ â”‚
â”‚ â”‚            settings = {                                          â”‚ â”‚
â”‚ â”‚                       â”‚   'dataset_path':                        â”‚ â”‚
â”‚ â”‚                       '/gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn29â€¦ â”‚ â”‚
â”‚ â”‚                       â”‚   'eval_dataset_path':                   â”‚ â”‚
â”‚ â”‚                       '/gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn29â€¦ â”‚ â”‚
â”‚ â”‚                       â”‚   'csv_path':                            â”‚ â”‚
â”‚ â”‚                       '/gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn29â€¦ â”‚ â”‚
â”‚ â”‚                       â”‚   'models': [                            â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   {                                  â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'model_name': 'LLaMa 3.1 8B',  â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'model_path':                  â”‚ â”‚
â”‚ â”‚                       '/home/iti/zn2950/home/haicore_ws/tunes/lâ€¦ â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'model_type':                  â”‚ â”‚
â”‚ â”‚                       'text-generation'                          â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   },                                 â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   {                                  â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'model_name': 'LLaMa 3.1 8B    â”‚ â”‚
â”‚ â”‚                       Instruct',                                 â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'model_path':                  â”‚ â”‚
â”‚ â”‚                       '/home/iti/zn2950/home/haicore_ws/tunes/lâ€¦ â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'model_type':                  â”‚ â”‚
â”‚ â”‚                       'text-generation'                          â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   }                                  â”‚ â”‚
â”‚ â”‚                       â”‚   ],                                     â”‚ â”‚
â”‚ â”‚                       â”‚   'extract_config': {                    â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   'additive': {                      â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'type': 'string',              â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'convert_funcs': ['ans2cid'],  â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'dataset_cols': [              â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   â”‚   'additive1'                â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   ]                              â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   },                                 â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   'solvent': {                       â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'type': 'string',              â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'convert_funcs': ['ans2cid'],  â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'dataset_cols': ['solvent1']   â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   },                                 â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   'temperature': {                   â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'type': 'number',              â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'unit': 'C',                   â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'convert_funcs': [             â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   â”‚   'ans2temperature'          â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   ],                             â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'dataset_cols': [              â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   â”‚   'temperature_Celsius'      â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   ]                              â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   },                                 â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   'time': {                          â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'type': 'number',              â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'unit': 'h',                   â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'convert_funcs': [             â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   â”‚   'ans2time'                 â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   ],                             â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   â”‚   'dataset_cols': ['time_h']     â”‚ â”‚
â”‚ â”‚                       â”‚   â”‚   }                                  â”‚ â”‚
â”‚ â”‚                       â”‚   }                                      â”‚ â”‚
â”‚ â”‚                       }                                          â”‚ â”‚
â”‚ â”‚               stats = []                                         â”‚ â”‚
â”‚ â”‚          stats_path = 'stats_llama_31_instruction_full_ft_with_â€¦ â”‚ â”‚
â”‚ â”‚         temperature = 0.0                                        â”‚ â”‚
â”‚ â”‚ valid_paragraph_ids = {                                          â”‚ â”‚
â”‚ â”‚                       â”‚   'HUYXOP_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'DACSAE_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'LELROL_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'NOBVOR_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'PEKZIP_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'TANLAX_charged',                      â”‚ â”‚
â”‚ â”‚                       â”‚   'WIVFIS_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'QARTEK_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'BAFCAP_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   'SUKYIH_clean',                        â”‚ â”‚
â”‚ â”‚                       â”‚   ... +768                               â”‚ â”‚
â”‚ â”‚                       }                                          â”‚ â”‚
â”‚ â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ â”‚
â”‚                                                                      â”‚
â”‚ /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/master_thesis/legacy_c â”‚
â”‚ ode/src/mthesis/models.py:64 in __init__                             â”‚
â”‚                                                                      â”‚
â”‚    61 â”‚   â”‚   â”‚   )                                                  â”‚
â”‚    62 â”‚   â”‚   â”‚   print("EOS_TOKEN: " + str(self.tokenizer.eos_token â”‚
â”‚    63 â”‚   â”‚   â”‚   print("PAD_TOKEN: " + str(self.tokenizer.pad_token â”‚
â”‚ â±  64 â”‚   â”‚   â”‚   print(tokenizer("Hello, my dog is cute").input_ids â”‚
â”‚    65 â”‚   â”‚   â”‚   if self.model_name == "Phi 3 Mini 4k Instruct":    â”‚
â”‚    66 â”‚   â”‚   â”‚   â”‚   # We have to use the max vocab size of 32064 f â”‚
â”‚    67 â”‚   â”‚   â”‚   â”‚   # For some reason only 32011 tokens are define â”‚
â”‚                                                                      â”‚
â”‚ â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ locals â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® â”‚
â”‚ â”‚    load_params = True                                            â”‚ â”‚
â”‚ â”‚   model_kwargs = {                                               â”‚ â”‚
â”‚ â”‚                  â”‚   'torch_dtype': torch.float16,               â”‚ â”‚
â”‚ â”‚                  â”‚   'load_in_8bit': False,                      â”‚ â”‚
â”‚ â”‚                  â”‚   'trust_remote_code': True,                  â”‚ â”‚
â”‚ â”‚                  â”‚   'device_map': 'auto',                       â”‚ â”‚
â”‚ â”‚                  â”‚   'do_sample': False                          â”‚ â”‚
â”‚ â”‚                  }                                               â”‚ â”‚
â”‚ â”‚     model_name = 'LLaMa 3.1 8B Instruct'                         â”‚ â”‚
â”‚ â”‚     model_path = '/home/iti/zn2950/home/haicore_ws/tunes/llama3â€¦ â”‚ â”‚
â”‚ â”‚     model_type = 'text-generation'                               â”‚ â”‚
â”‚ â”‚         prompt = 'Extract these synthesis conditions from the    â”‚ â”‚
â”‚ â”‚                  following Metal-Organic Framework (M'+385       â”‚ â”‚
â”‚ â”‚           self = JsonformerModel(                                â”‚ â”‚
â”‚ â”‚                    (model): LlamaForCausalLM(                    â”‚ â”‚
â”‚ â”‚                  â”‚   (model): LlamaModel(                        â”‚ â”‚
â”‚ â”‚                  â”‚     (embed_tokens): Embedding(128256, 4096)   â”‚ â”‚
â”‚ â”‚                  â”‚     (layers): ModuleList(                     â”‚ â”‚
â”‚ â”‚                  â”‚   â”‚   (0-31): 32 x LlamaDecoderLayer(         â”‚ â”‚
â”‚ â”‚                  â”‚   â”‚     (self_attn): LlamaSdpaAttention(      â”‚ â”‚
â”‚ â”‚                  â”‚   â”‚   â”‚   (q_proj): Linear(in_features=4096,  â”‚ â”‚
â”‚ â”‚                  out_features=4096, bias=False)                  â”‚ â”‚
â”‚ â”‚                  â”‚   â”‚   â”‚   (k_proj): Linear(in_features=4096,  â”‚ â”‚
â”‚ â”‚                  out_features=1024, bias=False)                  â”‚ â”‚
â”‚ â”‚                  â”‚   â”‚   â”‚   (v_proj): Linear(in_features=4096,  â”‚ â”‚
â”‚ â”‚                  out_features=1024, bias=False)                  â”‚ â”‚
â”‚ â”‚                  â”‚   â”‚   â”‚   (o_proj): Linear(in_features=4096,  â”‚ â”‚
â”‚ â”‚                  out_features=4096, bias=False)                  â”‚ â”‚
â”‚ â”‚                  â”‚   â”‚   â”‚   (rotary_emb):                       â”‚ â”‚
â”‚ â”‚                  LlamaRotaryEmbedding()                          â”‚ â”‚
â”‚ â”‚                  â”‚   â”‚     )                                     â”‚ â”‚
â”‚ â”‚                  â”‚   â”‚     (mlp): LlamaMLP(                      â”‚ â”‚
â”‚ â”‚                  â”‚   â”‚   â”‚   (gate_proj):                        â”‚ â”‚
â”‚ â”‚                  Linear(in_features=4096, out_features=14336,    â”‚ â”‚
â”‚ â”‚                  bias=False)                                     â”‚ â”‚
â”‚ â”‚                  â”‚   â”‚   â”‚   (up_proj): Linear(in_features=4096, â”‚ â”‚
â”‚ â”‚                  out_features=14336, bias=False)                 â”‚ â”‚
â”‚ â”‚                  â”‚   â”‚   â”‚   (down_proj):                        â”‚ â”‚
â”‚ â”‚                  Linear(in_features=14336, out_features=4096,    â”‚ â”‚
â”‚ â”‚                  bias=False)                                     â”‚ â”‚
â”‚ â”‚                  â”‚   â”‚   â”‚   (act_fn): SiLU()                    â”‚ â”‚
â”‚ â”‚                  â”‚   â”‚     )                                     â”‚ â”‚
â”‚ â”‚                  â”‚   â”‚     (input_layernorm):                    â”‚ â”‚
â”‚ â”‚                  LlamaRMSNorm((4096,), eps=1e-05)                â”‚ â”‚
â”‚ â”‚                  â”‚   â”‚     (post_attention_layernorm):           â”‚ â”‚
â”‚ â”‚                  LlamaRMSNorm((4096,), eps=1e-05)                â”‚ â”‚
â”‚ â”‚                  â”‚   â”‚   )                                       â”‚ â”‚
â”‚ â”‚                  â”‚     )                                         â”‚ â”‚
â”‚ â”‚                  â”‚     (norm): LlamaRMSNorm((4096,), eps=1e-05)  â”‚ â”‚
â”‚ â”‚                  â”‚     (rotary_emb): LlamaRotaryEmbedding()      â”‚ â”‚
â”‚ â”‚                  â”‚   )                                           â”‚ â”‚
â”‚ â”‚                  â”‚   (lm_head): Linear(in_features=4096,         â”‚ â”‚
â”‚ â”‚                  out_features=128256, bias=False)                â”‚ â”‚
â”‚ â”‚                    )                                             â”‚ â”‚
â”‚ â”‚                  )                                               â”‚ â”‚
â”‚ â”‚    temperature = 0.0                                             â”‚ â”‚
â”‚ â”‚ tokenizer_path = None                                            â”‚ â”‚
â”‚ â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
NameError: name 'tokenizer' is not defined
model kwargs: {'torch_dtype': torch.float16, 'load_in_8bit': False, 'trust_remote_code': True, 'device_map': 'auto', 'do_sample': False}
EOS_TOKEN: 128009
PAD_TOKEN: None
