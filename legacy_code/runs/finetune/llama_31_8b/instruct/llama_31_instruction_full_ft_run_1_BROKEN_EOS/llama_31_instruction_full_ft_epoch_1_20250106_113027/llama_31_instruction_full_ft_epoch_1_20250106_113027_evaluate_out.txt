2025-01-06 11:30:31,278 INFO     Loading settings and stats
2025-01-06 11:30:31,278 INFO     Using prompt: , temperature: 0.1
2025-01-06 11:30:31,281 DEBUG    Settings loaded. CSV path: /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/tobias/SynMOF_M_out.csv
2025-01-06 11:30:31,281 WARNING  [Errno 2] No such file or directory: 'stats_llama_31_instruction_full_ft_epoch_1_20250106_113027.yml'
2025-01-06 11:30:31,281 WARNING  [Errno 2] No such file or directory: 'stats_llama_31_instruction_full_ft_epoch_1_20250106_113027.yaml'
2025-01-06 11:30:31,281 WARNING  Could not load 'stats_llama_31_instruction_full_ft_epoch_1_20250106_113027.yml', creating it (empty)
2025-01-06 11:30:31,290 INFO     Loading labels from CSV file: /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/tobias/SynMOF_M_out.csv
2025-01-06 11:30:31,295 INFO     Found 778 paragraphs with labels
2025-01-06 11:30:31,295 DEBUG    First few valid IDs: ['LATPIG_clean', 'YAFJEX_clean', 'WUDQIW_clean', 'DOKHUH_clean', 'NORPIV_clean']
2025-01-06 11:30:31,295 INFO     Loading evaluation set instead of regular dataset.
2025-01-06 11:30:31,295 DEBUG    Already evaluated: 0 items
2025-01-06 11:30:31,295 INFO     Loading Dataset from /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/eval_paragraphs
2025-01-06 11:30:31,295 INFO     Loading MOFDataset from '/gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/eval_paragraphs'
2025-01-06 11:30:31,299 INFO     Dataset loaded with 77 items
2025-01-06 11:30:31,299 INFO     Found 77 paragraphs that have labels in dataset
2025-01-06 11:30:31,299 DEBUG    First few overlapping IDs: ['ILOJEZ_clean', 'NEFTUP_clean', 'GUJREK_clean', 'NAWKII_clean', 'KUSQUM_clean']
2025-01-06 11:30:31,299 INFO     Processing model: LLaMa 3.1 8B
2025-01-06 11:30:31,299 INFO     Skipping model [LLaMa 3.1 8B]
2025-01-06 11:30:31,299 INFO     Processing model: LLaMa 3.1 8B Instruct
2025-01-06 11:30:31,301 INFO       0%|          | 0/77 [00:00<?, ?it/s, LLaMa 3.1 8B Instruct]
2025-01-06 11:30:31,301 INFO     Loading Model [LLaMa 3.1 8B Instruct] from /home/iti/zn2950/home/haicore_ws/tunes/llama31_8b/instruction_full_ft/run_1_1736114112/epoch_1
The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
/home/iti/zn2950/miniconda3/envs/llm-extraction/lib/python3.11/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/iti/zn2950/miniconda3/envs/llm-extraction did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...
  warn(msg)
2025-01-06 11:30:32,301 INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
  0%|          | 0/77 [00:00<?, ?it/s, LLaMa 3.1 8B Instruct]

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /home/iti/zn2950/miniconda3/envs/llm-extraction/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cuda118.so
CUDA SETUP: CUDA runtime path found: /software/all/devel/cuda/11.8/lib64/libcudart.so.11.0
CUDA SETUP: Highest compute capability among GPUs detected: 8.0
CUDA SETUP: Detected CUDA version 118
CUDA SETUP: Loading binary /home/iti/zn2950/miniconda3/envs/llm-extraction/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][A
Loading checkpoint shards:  25%|██▌       | 1/4 [00:07<00:21,  7.13s/it][A
Loading checkpoint shards:  50%|█████     | 2/4 [00:14<00:14,  7.25s/it][A
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:21<00:07,  7.25s/it][A
Loading checkpoint shards: 100%|██████████| 4/4 [00:23<00:00,  5.08s/it][ALoading checkpoint shards: 100%|██████████| 4/4 [00:23<00:00,  5.87s/it]
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
2025-01-06 11:30:59,837 INFO       1%|▏         | 1/77 [00:28<36:08, 28.54s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:31:03,126 INFO       3%|▎         | 2/77 [00:31<17:06, 13.68s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:31:06,882 INFO       4%|▍         | 3/77 [00:35<11:17,  9.15s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:31:10,132 INFO       5%|▌         | 4/77 [00:38<08:17,  6.82s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:31:14,873 INFO       6%|▋         | 5/77 [00:43<07:17,  6.07s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:31:18,748 INFO       8%|▊         | 6/77 [00:47<06:18,  5.32s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:31:22,107 INFO       9%|▉         | 7/77 [00:50<05:27,  4.68s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:31:25,635 INFO      10%|█         | 8/77 [00:54<04:57,  4.31s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:31:29,082 INFO      12%|█▏        | 9/77 [00:57<04:34,  4.04s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:31:32,183 INFO      13%|█▎        | 10/77 [01:00<04:11,  3.75s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:31:35,472 INFO      14%|█▍        | 11/77 [01:04<03:58,  3.61s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:31:38,993 INFO      16%|█▌        | 12/77 [01:07<03:52,  3.58s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:31:44,043 INFO      17%|█▋        | 13/77 [01:12<04:17,  4.03s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:31:47,521 INFO      18%|█▊        | 14/77 [01:16<04:03,  3.86s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:31:50,807 INFO      19%|█▉        | 15/77 [01:19<03:48,  3.69s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:31:54,297 INFO      21%|██        | 16/77 [01:22<03:41,  3.63s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:31:58,732 INFO      22%|██▏       | 17/77 [01:27<03:52,  3.87s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:32:02,593 INFO      23%|██▎       | 18/77 [01:31<03:48,  3.87s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:32:06,082 INFO      25%|██▍       | 19/77 [01:34<03:37,  3.75s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:32:10,124 INFO     Saving progress to `stats_llama_31_instruction_full_ft_epoch_1_20250106_113027.yml`
2025-01-06 11:32:10,142 INFO      26%|██▌       | 20/77 [01:38<03:39,  3.85s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:32:13,915 INFO      27%|██▋       | 21/77 [01:42<03:34,  3.82s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:32:17,299 INFO      29%|██▊       | 22/77 [01:45<03:23,  3.69s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:32:20,702 INFO      30%|██▉       | 23/77 [01:49<03:14,  3.61s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:32:24,227 INFO      31%|███       | 24/77 [01:52<03:09,  3.58s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:32:28,544 INFO      32%|███▏      | 25/77 [01:57<03:17,  3.80s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:32:32,096 INFO      34%|███▍      | 26/77 [02:00<03:10,  3.73s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:32:36,015 INFO      35%|███▌      | 27/77 [02:04<03:09,  3.78s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:32:39,377 INFO      36%|███▋      | 28/77 [02:08<02:59,  3.66s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:32:42,907 INFO      38%|███▊      | 29/77 [02:11<02:53,  3.62s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:32:46,666 INFO      39%|███▉      | 30/77 [02:15<02:52,  3.66s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:32:50,598 INFO      40%|████      | 31/77 [02:19<02:52,  3.74s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:32:54,151 INFO      42%|████▏     | 32/77 [02:22<02:45,  3.69s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:32:57,641 INFO      43%|████▎     | 33/77 [02:26<02:39,  3.63s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:33:01,474 INFO      44%|████▍     | 34/77 [02:30<02:38,  3.69s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:33:05,775 INFO      45%|████▌     | 35/77 [02:34<02:42,  3.87s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:33:09,473 INFO      47%|████▋     | 36/77 [02:38<02:36,  3.82s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:33:14,605 INFO      48%|████▊     | 37/77 [02:43<02:48,  4.21s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:33:18,382 INFO      49%|████▉     | 38/77 [02:47<02:39,  4.08s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:33:21,953 INFO      51%|█████     | 39/77 [02:50<02:29,  3.93s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:33:25,419 INFO     Saving progress to `stats_llama_31_instruction_full_ft_epoch_1_20250106_113027.yml`
2025-01-06 11:33:25,439 INFO      52%|█████▏    | 40/77 [02:54<02:20,  3.80s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:33:28,658 INFO      53%|█████▎    | 41/77 [02:57<02:10,  3.62s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:33:32,138 INFO      55%|█████▍    | 42/77 [03:00<02:05,  3.58s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:33:36,374 INFO      56%|█████▌    | 43/77 [03:05<02:08,  3.78s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:33:39,972 INFO      57%|█████▋    | 44/77 [03:08<02:02,  3.72s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:33:43,585 INFO      58%|█████▊    | 45/77 [03:12<01:58,  3.69s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:33:47,162 INFO      60%|█████▉    | 46/77 [03:15<01:53,  3.66s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:33:50,705 INFO      61%|██████    | 47/77 [03:19<01:48,  3.62s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:33:54,166 INFO      62%|██████▏   | 48/77 [03:22<01:43,  3.57s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:33:57,590 INFO      64%|██████▎   | 49/77 [03:26<01:38,  3.53s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:34:01,020 INFO      65%|██████▍   | 50/77 [03:29<01:34,  3.50s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:34:05,203 INFO      66%|██████▌   | 51/77 [03:33<01:36,  3.70s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:34:08,765 INFO      68%|██████▊   | 52/77 [03:37<01:31,  3.66s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:34:12,323 INFO      69%|██████▉   | 53/77 [03:41<01:27,  3.63s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:34:16,010 INFO      70%|███████   | 54/77 [03:44<01:23,  3.65s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:34:19,506 INFO      71%|███████▏  | 55/77 [03:48<01:19,  3.60s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:34:22,674 INFO      73%|███████▎  | 56/77 [03:51<01:12,  3.47s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:34:26,126 INFO      74%|███████▍  | 57/77 [03:54<01:09,  3.47s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:34:29,541 INFO      75%|███████▌  | 58/77 [03:58<01:05,  3.45s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:34:33,087 INFO      77%|███████▋  | 59/77 [04:01<01:02,  3.48s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:34:36,503 INFO     Saving progress to `stats_llama_31_instruction_full_ft_epoch_1_20250106_113027.yml`
2025-01-06 11:34:36,537 INFO      78%|███████▊  | 60/77 [04:05<00:58,  3.47s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:34:40,099 INFO      79%|███████▉  | 61/77 [04:08<00:55,  3.50s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:34:43,635 INFO      81%|████████  | 62/77 [04:12<00:52,  3.51s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:34:47,691 INFO      82%|████████▏ | 63/77 [04:16<00:51,  3.67s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:34:51,304 INFO      83%|████████▎ | 64/77 [04:20<00:47,  3.66s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:34:54,834 INFO      84%|████████▍ | 65/77 [04:23<00:43,  3.62s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:34:58,396 INFO      86%|████████▌ | 66/77 [04:27<00:39,  3.60s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:35:02,182 INFO      87%|████████▋ | 67/77 [04:30<00:36,  3.66s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:35:05,761 INFO      88%|████████▊ | 68/77 [04:34<00:32,  3.63s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:35:09,038 INFO      90%|████████▉ | 69/77 [04:37<00:28,  3.53s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:35:12,938 INFO      91%|█████████ | 70/77 [04:41<00:25,  3.64s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:35:16,235 INFO      92%|█████████▏| 71/77 [04:44<00:21,  3.54s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:35:19,720 INFO      94%|█████████▎| 72/77 [04:48<00:17,  3.52s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:35:22,923 INFO      95%|█████████▍| 73/77 [04:51<00:13,  3.43s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:35:26,538 INFO      96%|█████████▌| 74/77 [04:55<00:10,  3.48s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:35:30,650 INFO      97%|█████████▋| 75/77 [04:59<00:07,  3.67s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:35:34,467 INFO      99%|█████████▊| 76/77 [05:03<00:03,  3.71s/it, LLaMa 3.1 8B Instruct]
2025-01-06 11:35:38,096 INFO     Saving progress to `stats_llama_31_instruction_full_ft_epoch_1_20250106_113027.yml`
  1%|▏         | 1/77 [00:28<36:08, 28.54s/it, LLaMa 3.1 8B Instruct]
  3%|▎         | 2/77 [00:31<17:06, 13.68s/it, LLaMa 3.1 8B Instruct]
  4%|▍         | 3/77 [00:35<11:17,  9.15s/it, LLaMa 3.1 8B Instruct]
  5%|▌         | 4/77 [00:38<08:17,  6.82s/it, LLaMa 3.1 8B Instruct]
  6%|▋         | 5/77 [00:43<07:17,  6.07s/it, LLaMa 3.1 8B Instruct]
  8%|▊         | 6/77 [00:47<06:18,  5.32s/it, LLaMa 3.1 8B Instruct]
  9%|▉         | 7/77 [00:50<05:27,  4.68s/it, LLaMa 3.1 8B Instruct]
 10%|█         | 8/77 [00:54<04:57,  4.31s/it, LLaMa 3.1 8B Instruct]
 12%|█▏        | 9/77 [00:57<04:34,  4.04s/it, LLaMa 3.1 8B Instruct]
 13%|█▎        | 10/77 [01:00<04:11,  3.75s/it, LLaMa 3.1 8B Instruct]
 14%|█▍        | 11/77 [01:04<03:58,  3.61s/it, LLaMa 3.1 8B Instruct]
 16%|█▌        | 12/77 [01:07<03:52,  3.58s/it, LLaMa 3.1 8B Instruct]
 17%|█▋        | 13/77 [01:12<04:17,  4.03s/it, LLaMa 3.1 8B Instruct]
 18%|█▊        | 14/77 [01:16<04:03,  3.86s/it, LLaMa 3.1 8B Instruct]
 19%|█▉        | 15/77 [01:19<03:48,  3.69s/it, LLaMa 3.1 8B Instruct]
 21%|██        | 16/77 [01:22<03:41,  3.63s/it, LLaMa 3.1 8B Instruct]
 22%|██▏       | 17/77 [01:27<03:52,  3.87s/it, LLaMa 3.1 8B Instruct]
 23%|██▎       | 18/77 [01:31<03:48,  3.87s/it, LLaMa 3.1 8B Instruct]
 25%|██▍       | 19/77 [01:34<03:37,  3.75s/it, LLaMa 3.1 8B Instruct]
 26%|██▌       | 20/77 [01:38<03:39,  3.85s/it, LLaMa 3.1 8B Instruct]
 27%|██▋       | 21/77 [01:42<03:34,  3.82s/it, LLaMa 3.1 8B Instruct]
 29%|██▊       | 22/77 [01:45<03:23,  3.69s/it, LLaMa 3.1 8B Instruct]
 30%|██▉       | 23/77 [01:49<03:14,  3.61s/it, LLaMa 3.1 8B Instruct]
 31%|███       | 24/77 [01:52<03:09,  3.58s/it, LLaMa 3.1 8B Instruct]
 32%|███▏      | 25/77 [01:57<03:17,  3.80s/it, LLaMa 3.1 8B Instruct]
 34%|███▍      | 26/77 [02:00<03:10,  3.73s/it, LLaMa 3.1 8B Instruct]
 35%|███▌      | 27/77 [02:04<03:09,  3.78s/it, LLaMa 3.1 8B Instruct]
 36%|███▋      | 28/77 [02:08<02:59,  3.66s/it, LLaMa 3.1 8B Instruct]
 38%|███▊      | 29/77 [02:11<02:53,  3.62s/it, LLaMa 3.1 8B Instruct]
 39%|███▉      | 30/77 [02:15<02:52,  3.66s/it, LLaMa 3.1 8B Instruct]
 40%|████      | 31/77 [02:19<02:52,  3.74s/it, LLaMa 3.1 8B Instruct]
 42%|████▏     | 32/77 [02:22<02:45,  3.69s/it, LLaMa 3.1 8B Instruct]
 43%|████▎     | 33/77 [02:26<02:39,  3.63s/it, LLaMa 3.1 8B Instruct]
 44%|████▍     | 34/77 [02:30<02:38,  3.69s/it, LLaMa 3.1 8B Instruct]
 45%|████▌     | 35/77 [02:34<02:42,  3.87s/it, LLaMa 3.1 8B Instruct]
 47%|████▋     | 36/77 [02:38<02:36,  3.82s/it, LLaMa 3.1 8B Instruct]
 48%|████▊     | 37/77 [02:43<02:48,  4.21s/it, LLaMa 3.1 8B Instruct]
 49%|████▉     | 38/77 [02:47<02:39,  4.08s/it, LLaMa 3.1 8B Instruct]
 51%|█████     | 39/77 [02:50<02:29,  3.93s/it, LLaMa 3.1 8B Instruct]
 52%|█████▏    | 40/77 [02:54<02:20,  3.80s/it, LLaMa 3.1 8B Instruct]
 53%|█████▎    | 41/77 [02:57<02:10,  3.62s/it, LLaMa 3.1 8B Instruct]
 55%|█████▍    | 42/77 [03:00<02:05,  3.58s/it, LLaMa 3.1 8B Instruct]
 56%|█████▌    | 43/77 [03:05<02:08,  3.78s/it, LLaMa 3.1 8B Instruct]
 57%|█████▋    | 44/77 [03:08<02:02,  3.72s/it, LLaMa 3.1 8B Instruct]
 58%|█████▊    | 45/77 [03:12<01:58,  3.69s/it, LLaMa 3.1 8B Instruct]
 60%|█████▉    | 46/77 [03:15<01:53,  3.66s/it, LLaMa 3.1 8B Instruct]
 61%|██████    | 47/77 [03:19<01:48,  3.62s/it, LLaMa 3.1 8B Instruct]
 62%|██████▏   | 48/77 [03:22<01:43,  3.57s/it, LLaMa 3.1 8B Instruct]
 64%|██████▎   | 49/77 [03:26<01:38,  3.53s/it, LLaMa 3.1 8B Instruct]
 65%|██████▍   | 50/77 [03:29<01:34,  3.50s/it, LLaMa 3.1 8B Instruct]
 66%|██████▌   | 51/77 [03:33<01:36,  3.70s/it, LLaMa 3.1 8B Instruct]
 68%|██████▊   | 52/77 [03:37<01:31,  3.66s/it, LLaMa 3.1 8B Instruct]
 69%|██████▉   | 53/77 [03:41<01:27,  3.63s/it, LLaMa 3.1 8B Instruct]
 70%|███████   | 54/77 [03:44<01:23,  3.65s/it, LLaMa 3.1 8B Instruct]
 71%|███████▏  | 55/77 [03:48<01:19,  3.60s/it, LLaMa 3.1 8B Instruct]
 73%|███████▎  | 56/77 [03:51<01:12,  3.47s/it, LLaMa 3.1 8B Instruct]
 74%|███████▍  | 57/77 [03:54<01:09,  3.47s/it, LLaMa 3.1 8B Instruct]
 75%|███████▌  | 58/77 [03:58<01:05,  3.45s/it, LLaMa 3.1 8B Instruct]
 77%|███████▋  | 59/77 [04:01<01:02,  3.48s/it, LLaMa 3.1 8B Instruct]
 78%|███████▊  | 60/77 [04:05<00:58,  3.47s/it, LLaMa 3.1 8B Instruct]
 79%|███████▉  | 61/77 [04:08<00:55,  3.50s/it, LLaMa 3.1 8B Instruct]
 81%|████████  | 62/77 [04:12<00:52,  3.51s/it, LLaMa 3.1 8B Instruct]
 82%|████████▏ | 63/77 [04:16<00:51,  3.67s/it, LLaMa 3.1 8B Instruct]
 83%|████████▎ | 64/77 [04:20<00:47,  3.66s/it, LLaMa 3.1 8B Instruct]
 84%|████████▍ | 65/77 [04:23<00:43,  3.62s/it, LLaMa 3.1 8B Instruct]
 86%|████████▌ | 66/77 [04:27<00:39,  3.60s/it, LLaMa 3.1 8B Instruct]
 87%|████████▋ | 67/77 [04:30<00:36,  3.66s/it, LLaMa 3.1 8B Instruct]
 88%|████████▊ | 68/77 [04:34<00:32,  3.63s/it, LLaMa 3.1 8B Instruct]
 90%|████████▉ | 69/77 [04:37<00:28,  3.53s/it, LLaMa 3.1 8B Instruct]
 91%|█████████ | 70/77 [04:41<00:25,  3.64s/it, LLaMa 3.1 8B Instruct]
 92%|█████████▏| 71/77 [04:44<00:21,  3.54s/it, LLaMa 3.1 8B Instruct]
 94%|█████████▎| 72/77 [04:48<00:17,  3.52s/it, LLaMa 3.1 8B Instruct]
 95%|█████████▍| 73/77 [04:51<00:13,  3.43s/it, LLaMa 3.1 8B Instruct]
 96%|█████████▌| 74/77 [04:55<00:10,  3.48s/it, LLaMa 3.1 8B Instruct]
 97%|█████████▋| 75/77 [04:59<00:07,  3.67s/it, LLaMa 3.1 8B Instruct]
 99%|█████████▊| 76/77 [05:03<00:03,  3.71s/it, LLaMa 3.1 8B Instruct]
