2025-01-07 14:31:38,486 INFO     Loading settings and stats
2025-01-07 14:31:38,486 INFO     Using prompt: Read the following Metal-Organic Framework (MOF) synthesis description and extract this information: temperature (highest reaction temp, use 25°C if not specified), time (longest duration at highest temp), one main solvent (no mixtures or ratios), one chemical additive ('None' if no additive present). Important: Do not use JSON or curly braces in your output, they are already provided for you and you do not need to generate them. Only output the extracted information and terminate strings with ", temperature: 0.0
2025-01-07 14:31:38,489 DEBUG    Settings loaded. CSV path: /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/tobias/SynMOF_M_out.csv
2025-01-07 14:31:38,489 WARNING  [Errno 2] No such file or directory: 'stats_llama_31_text_full_ft_epoch_8_20250107_143134.yml'
2025-01-07 14:31:38,489 WARNING  [Errno 2] No such file or directory: 'stats_llama_31_text_full_ft_epoch_8_20250107_143134.yaml'
2025-01-07 14:31:38,489 WARNING  Could not load 'stats_llama_31_text_full_ft_epoch_8_20250107_143134.yml', creating it (empty)
2025-01-07 14:31:38,491 INFO     Loading labels from CSV file: /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/tobias/SynMOF_M_out.csv
2025-01-07 14:31:38,496 INFO     Found 778 paragraphs with labels
2025-01-07 14:31:38,497 DEBUG    First few valid IDs: ['SAMXUC_clean', 'HABZEQ_clean', 'BIHMUC_clean', 'ACALIB_clean', 'OGUPIQ_clean']
2025-01-07 14:31:38,497 INFO     Loading evaluation set instead of regular dataset.
2025-01-07 14:31:38,497 DEBUG    Already evaluated: 0 items
2025-01-07 14:31:38,497 INFO     Loading Dataset from /gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/eval_paragraphs
2025-01-07 14:31:38,497 INFO     Loading MOFDataset from '/gfse/data/LSDF/lsdf01/lsdf/kit/iti/zn2950/ws/data/eval_paragraphs'
2025-01-07 14:31:38,502 INFO     Dataset loaded with 77 items
2025-01-07 14:31:38,502 INFO     Found 77 paragraphs that have labels in dataset
2025-01-07 14:31:38,502 DEBUG    First few overlapping IDs: ['LAHTUM_clean', 'MAZSUD_clean', 'BIHMUC_clean', 'XUKNIC_clean', 'KUQWIE_clean']
2025-01-07 14:31:38,502 INFO     Processing model: LLaMa 3.1 8B
2025-01-07 14:31:38,502 INFO     Skipping model [LLaMa 3.1 8B]
2025-01-07 14:31:38,502 INFO     Processing model: LLaMa 3.1 8B Instruct
2025-01-07 14:31:38,504 INFO       0%|          | 0/77 [00:00<?, ?it/s, LLaMa 3.1 8B Instruct]
2025-01-07 14:31:38,504 INFO     Loading Model [LLaMa 3.1 8B Instruct] from /home/iti/zn2950/home/haicore_ws/tunes/llama31_8b/text_completion_full_ft/run_2_1736251386_LOW_LR/epoch_8
2025-01-07 14:31:39,186 INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-01-07 14:31:54,949 INFO       1%|▏         | 1/77 [00:16<20:49, 16.45s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:31:56,674 INFO       3%|▎         | 2/77 [00:18<09:43,  7.79s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:31:58,328 INFO       4%|▍         | 3/77 [00:19<06:08,  4.99s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:31:59,888 INFO       5%|▌         | 4/77 [00:21<04:25,  3.63s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:01,437 INFO       6%|▋         | 5/77 [00:22<03:27,  2.88s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:02,967 INFO       8%|▊         | 6/77 [00:24<02:51,  2.42s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:04,613 INFO       9%|▉         | 7/77 [00:26<02:31,  2.17s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:06,218 INFO      10%|█         | 8/77 [00:27<02:17,  1.99s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:07,761 INFO      12%|█▏        | 9/77 [00:29<02:05,  1.85s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:09,310 INFO      13%|█▎        | 10/77 [00:30<01:57,  1.76s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:10,880 INFO      14%|█▍        | 11/77 [00:32<01:52,  1.70s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:12,389 INFO      16%|█▌        | 12/77 [00:33<01:46,  1.64s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:14,069 INFO      17%|█▋        | 13/77 [00:35<01:45,  1.65s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:15,663 INFO      18%|█▊        | 14/77 [00:37<01:43,  1.64s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:17,203 INFO      19%|█▉        | 15/77 [00:38<01:39,  1.61s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:18,829 INFO      21%|██        | 16/77 [00:40<01:38,  1.61s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:20,472 INFO      22%|██▏       | 17/77 [00:41<01:37,  1.62s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:22,122 INFO      23%|██▎       | 18/77 [00:43<01:36,  1.63s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:23,710 INFO      25%|██▍       | 19/77 [00:45<01:33,  1.62s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:25,316 INFO     Saving progress to `stats_llama_31_text_full_ft_epoch_8_20250107_143134.yml`
2025-01-07 14:32:25,331 INFO      26%|██▌       | 20/77 [00:46<01:32,  1.62s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:26,891 INFO      27%|██▋       | 21/77 [00:48<01:29,  1.60s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:28,460 INFO      29%|██▊       | 22/77 [00:49<01:27,  1.59s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:30,014 INFO      30%|██▉       | 23/77 [00:51<01:25,  1.58s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:31,613 INFO      31%|███       | 24/77 [00:53<01:24,  1.59s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:33,133 INFO      32%|███▏      | 25/77 [00:54<01:21,  1.57s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:34,689 INFO      34%|███▍      | 26/77 [00:56<01:19,  1.56s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:36,259 INFO      35%|███▌      | 27/77 [00:57<01:18,  1.57s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:37,940 INFO      36%|███▋      | 28/77 [00:59<01:18,  1.60s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:39,497 INFO      38%|███▊      | 29/77 [01:00<01:16,  1.59s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:41,124 INFO      39%|███▉      | 30/77 [01:02<01:15,  1.60s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:42,756 INFO      40%|████      | 31/77 [01:04<01:14,  1.61s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:44,369 INFO      42%|████▏     | 32/77 [01:05<01:12,  1.61s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:45,965 INFO      43%|████▎     | 33/77 [01:07<01:10,  1.61s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:47,594 INFO      44%|████▍     | 34/77 [01:09<01:09,  1.61s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:49,205 INFO      45%|████▌     | 35/77 [01:10<01:07,  1.61s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:50,890 INFO      47%|████▋     | 36/77 [01:12<01:06,  1.63s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:52,521 INFO      48%|████▊     | 37/77 [01:14<01:05,  1.63s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:54,065 INFO      49%|████▉     | 38/77 [01:15<01:02,  1.61s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:55,685 INFO      51%|█████     | 39/77 [01:17<01:01,  1.61s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:57,222 INFO     Saving progress to `stats_llama_31_text_full_ft_epoch_8_20250107_143134.yml`
2025-01-07 14:32:57,249 INFO      52%|█████▏    | 40/77 [01:18<00:59,  1.60s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:32:59,001 INFO      53%|█████▎    | 41/77 [01:20<00:59,  1.64s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:00,587 INFO      55%|█████▍    | 42/77 [01:22<00:56,  1.63s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:02,154 INFO      56%|█████▌    | 43/77 [01:23<00:54,  1.61s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:03,724 INFO      57%|█████▋    | 44/77 [01:25<00:52,  1.60s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:05,343 INFO      58%|█████▊    | 45/77 [01:26<00:51,  1.60s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:06,890 INFO      60%|█████▉    | 46/77 [01:28<00:49,  1.59s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:08,505 INFO      61%|██████    | 47/77 [01:30<00:47,  1.59s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:10,146 INFO      62%|██████▏   | 48/77 [01:31<00:46,  1.61s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:11,711 INFO      64%|██████▎   | 49/77 [01:33<00:44,  1.60s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:13,229 INFO      65%|██████▍   | 50/77 [01:34<00:42,  1.57s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:14,798 INFO      66%|██████▌   | 51/77 [01:36<00:40,  1.57s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:16,416 INFO      68%|██████▊   | 52/77 [01:37<00:39,  1.59s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:18,074 INFO      69%|██████▉   | 53/77 [01:39<00:38,  1.61s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:19,643 INFO      70%|███████   | 54/77 [01:41<00:36,  1.60s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:21,183 INFO      71%|███████▏  | 55/77 [01:42<00:34,  1.58s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:22,750 INFO      73%|███████▎  | 56/77 [01:44<00:33,  1.58s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:24,288 INFO      74%|███████▍  | 57/77 [01:45<00:31,  1.56s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:26,047 INFO      75%|███████▌  | 58/77 [01:47<00:30,  1.62s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:27,729 INFO      77%|███████▋  | 59/77 [01:49<00:29,  1.64s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:29,349 INFO     Saving progress to `stats_llama_31_text_full_ft_epoch_8_20250107_143134.yml`
2025-01-07 14:33:29,386 INFO      78%|███████▊  | 60/77 [01:50<00:27,  1.65s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:31,002 INFO      79%|███████▉  | 61/77 [01:52<00:26,  1.64s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:32,682 INFO      81%|████████  | 62/77 [01:54<00:24,  1.65s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:34,244 INFO      82%|████████▏ | 63/77 [01:55<00:22,  1.62s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:35,958 INFO      83%|████████▎ | 64/77 [01:57<00:21,  1.65s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:37,575 INFO      84%|████████▍ | 65/77 [01:59<00:19,  1.64s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:39,148 INFO      86%|████████▌ | 66/77 [02:00<00:17,  1.62s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:40,844 INFO      87%|████████▋ | 67/77 [02:02<00:16,  1.64s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:42,487 INFO      88%|████████▊ | 68/77 [02:03<00:14,  1.64s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:44,032 INFO      90%|████████▉ | 69/77 [02:05<00:12,  1.61s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:45,766 INFO      91%|█████████ | 70/77 [02:07<00:11,  1.65s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:47,329 INFO      92%|█████████▏| 71/77 [02:08<00:09,  1.62s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:48,945 INFO      94%|█████████▎| 72/77 [02:10<00:08,  1.62s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:50,638 INFO      95%|█████████▍| 73/77 [02:12<00:06,  1.64s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:52,193 INFO      96%|█████████▌| 74/77 [02:13<00:04,  1.62s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:53,697 INFO      97%|█████████▋| 75/77 [02:15<00:03,  1.58s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:55,344 INFO      99%|█████████▊| 76/77 [02:16<00:01,  1.60s/it, LLaMa 3.1 8B Instruct]
2025-01-07 14:33:57,034 INFO     Saving progress to `stats_llama_31_text_full_ft_epoch_8_20250107_143134.yml`
